apiVersion: v1
items:
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cni.projectcalico.org/podIP: 192.168.192.27/32
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"Pod","metadata":{"annotations":{},"labels":{"app":"log-extract"},"name":"foobar","namespace":"default"},"spec":{"containers":[{"image":"acinwinstack/cka-mock:log-extract","name":"foobar-container"}],"restartPolicy":"Never"}}
    creationTimestamp: "2020-06-15T06:25:12Z"
    labels:
      app: log-extract
    name: foobar
    namespace: default
    resourceVersion: "17891111"
    selfLink: /api/v1/namespaces/default/pods/foobar
    uid: 0728715d-63b7-4ca4-bb21-6c2afc81d7dd
  spec:
    containers:
    - image: acinwinstack/cka-mock:log-extract
      imagePullPolicy: IfNotPresent
      name: foobar-container
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: default-token-fh8hd
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: hk8s-worker2
    priority: 0
    restartPolicy: Never
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: default-token-fh8hd
      secret:
        defaultMode: 420
        secretName: default-token-fh8hd
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2020-06-15T06:25:12Z"
      reason: PodCompleted
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2020-06-15T06:25:12Z"
      reason: PodCompleted
      status: "False"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2020-06-15T06:25:12Z"
      reason: PodCompleted
      status: "False"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2020-06-15T06:25:12Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://d9a9e038d3f24e8d9c10acade72d60e29caca180cea1207561ceb80349e42d11
      image: acinwinstack/cka-mock:log-extract
      imageID: docker-pullable://acinwinstack/cka-mock@sha256:d22bc13f69f1856ac25c28691bfdacc9c392ccd09c0a9a7ccef0a6cb2a3117ce
      lastState: {}
      name: foobar-container
      ready: false
      restartCount: 0
      started: false
      state:
        terminated:
          containerID: docker://d9a9e038d3f24e8d9c10acade72d60e29caca180cea1207561ceb80349e42d11
          exitCode: 0
          finishedAt: "2020-06-15T06:25:14Z"
          reason: Completed
          startedAt: "2020-06-15T06:25:14Z"
    hostIP: 192.168.122.22
    phase: Succeeded
    podIP: 192.168.192.27
    podIPs:
    - ip: 192.168.192.27
    qosClass: BestEffort
    startTime: "2020-06-15T06:25:12Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cni.projectcalico.org/podIP: 192.168.192.55/32
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"Pod","metadata":{"annotations":{},"labels":{"app":"my-front-end"},"name":"front-end","namespace":"default"},"spec":{"containers":[{"image":"nginx","name":"nginx"}]}}
    creationTimestamp: "2020-06-15T06:25:31Z"
    labels:
      app: my-front-end
    name: front-end
    namespace: default
    resourceVersion: "17996855"
    selfLink: /api/v1/namespaces/default/pods/front-end
    uid: ac929ed9-d6b1-4295-b34d-3b6290cf2324
  spec:
    containers:
    - image: nginx
      imagePullPolicy: Always
      name: nginx
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: default-token-fh8hd
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: hk8s-worker2
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: default-token-fh8hd
      secret:
        defaultMode: 420
        secretName: default-token-fh8hd
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2020-06-15T06:25:31Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2020-06-17T05:57:12Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2020-06-17T05:57:12Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2020-06-15T06:25:31Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://64e94b0b08ca9f132883183e8634c3b6a81559dd8d912d712ba110351cdf6ea9
      image: nginx:latest
      imageID: docker-pullable://nginx@sha256:21f32f6c08406306d822a0e6e8b7dc81f53f336570e852e25fbe1e3e3d0d0133
      lastState:
        terminated:
          containerID: docker://6f8abc69447771cb61f1ac5c49c1e4baa0446358c718a513dfe73fd106c91072
          exitCode: 0
          finishedAt: "2020-06-16T02:18:30Z"
          reason: Completed
          startedAt: "2020-06-15T06:25:36Z"
      name: nginx
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2020-06-17T05:56:55Z"
    hostIP: 192.168.122.22
    phase: Running
    podIP: 192.168.192.55
    podIPs:
    - ip: 192.168.192.55
    qosClass: BestEffort
    startTime: "2020-06-15T06:25:31Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cni.projectcalico.org/podIP: 192.168.80.116/32
    creationTimestamp: "2020-06-15T06:26:30Z"
    generateName: guestbook-
    labels:
      app: nginx
    name: guestbook-dndpn
    namespace: default
    ownerReferences:
    - apiVersion: v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicationController
      name: guestbook
      uid: baed92ef-4a38-49ee-b71f-6b6f4b1ef8d6
    resourceVersion: "17996799"
    selfLink: /api/v1/namespaces/default/pods/guestbook-dndpn
    uid: a7c24d62-6f6f-4568-90e4-f13c2b7290ec
  spec:
    containers:
    - image: nginx
      imagePullPolicy: Always
      name: nginx
      ports:
      - containerPort: 80
        protocol: TCP
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: default-token-fh8hd
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: hk8s-worker1
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: default-token-fh8hd
      secret:
        defaultMode: 420
        secretName: default-token-fh8hd
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2020-06-15T06:26:30Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2020-06-17T05:57:06Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2020-06-17T05:57:06Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2020-06-15T06:26:30Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://51a32d8b14d7e3c02eaca68df96e9b1d077683c097ad5afbfa4a829b8f33a52b
      image: nginx:latest
      imageID: docker-pullable://nginx@sha256:21f32f6c08406306d822a0e6e8b7dc81f53f336570e852e25fbe1e3e3d0d0133
      lastState:
        terminated:
          containerID: docker://8e51c2c4ad7fb5d78ed3fec035651d64fbc36f33df7cd1adb1c5b4d5b44b6f75
          exitCode: 0
          finishedAt: "2020-06-16T02:18:24Z"
          reason: Completed
          startedAt: "2020-06-15T06:26:52Z"
      name: nginx
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2020-06-17T05:57:03Z"
    hostIP: 192.168.122.21
    phase: Running
    podIP: 192.168.80.116
    podIPs:
    - ip: 192.168.80.116
    qosClass: BestEffort
    startTime: "2020-06-15T06:26:30Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cni.projectcalico.org/podIP: 192.168.192.59/32
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"Pod","metadata":{"annotations":{},"labels":{"prob":"dns","test":"cka"},"name":"nginx-test","namespace":"default"},"spec":{"containers":[{"image":"nginx","name":"nginx"}]}}
    creationTimestamp: "2020-06-15T08:52:10Z"
    labels:
      prob: dns
      test: cka
    name: nginx-test
    namespace: default
    resourceVersion: "17996861"
    selfLink: /api/v1/namespaces/default/pods/nginx-test
    uid: ce797811-d7c1-459b-bfbc-f4d21f23cd03
  spec:
    containers:
    - image: nginx
      imagePullPolicy: Always
      name: nginx
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: default-token-fh8hd
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: hk8s-worker2
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: default-token-fh8hd
      secret:
        defaultMode: 420
        secretName: default-token-fh8hd
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2020-06-15T08:52:10Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2020-06-17T05:57:13Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2020-06-17T05:57:13Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2020-06-15T08:52:10Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://9706ed29a6980ec77de951b2c7aa0f7a59d09957be694c2e0d32de1b348277bc
      image: nginx:latest
      imageID: docker-pullable://nginx@sha256:21f32f6c08406306d822a0e6e8b7dc81f53f336570e852e25fbe1e3e3d0d0133
      lastState:
        terminated:
          containerID: docker://06c2cd9d845279d5282c6727228ab8b375b865c6644515421cc88fec2f730cf3
          exitCode: 0
          finishedAt: "2020-06-16T02:18:33Z"
          reason: Completed
          startedAt: "2020-06-15T08:52:16Z"
      name: nginx
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2020-06-17T05:57:12Z"
    hostIP: 192.168.122.22
    phase: Running
    podIP: 192.168.192.59
    podIPs:
    - ip: 192.168.192.59
    qosClass: BestEffort
    startTime: "2020-06-15T08:52:10Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cni.projectcalico.org/podIP: 192.168.192.58/32
    creationTimestamp: "2020-06-15T06:26:30Z"
    generateName: webserver-674cc76668-
    labels:
      app: nginx
      pod-template-hash: 674cc76668
    name: webserver-674cc76668-4fbpd
    namespace: default
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: webserver-674cc76668
      uid: 9c146749-aed1-4ef7-a7d5-66b134689ca7
    resourceVersion: "17996857"
    selfLink: /api/v1/namespaces/default/pods/webserver-674cc76668-4fbpd
    uid: d67f18e5-5d7f-4a16-9bec-1496a9c3e926
  spec:
    containers:
    - image: nginx
      imagePullPolicy: Always
      name: nginx
      ports:
      - containerPort: 80
        protocol: TCP
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: default-token-fh8hd
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: hk8s-worker2
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: default-token-fh8hd
      secret:
        defaultMode: 420
        secretName: default-token-fh8hd
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2020-06-15T06:26:30Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2020-06-17T05:57:13Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2020-06-17T05:57:13Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2020-06-15T06:26:30Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://6da304e02dc72f5b1f4eb070f8372f4e77c4ab5f7336cfe73152921dde3ba201
      image: nginx:latest
      imageID: docker-pullable://nginx@sha256:21f32f6c08406306d822a0e6e8b7dc81f53f336570e852e25fbe1e3e3d0d0133
      lastState:
        terminated:
          containerID: docker://f6788c795e67ead8332c36b4ea14a9022f54020007a29496177aab6cc0002cac
          exitCode: 0
          finishedAt: "2020-06-16T02:18:29Z"
          reason: Completed
          startedAt: "2020-06-15T06:26:42Z"
      name: nginx
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2020-06-17T05:57:08Z"
    hostIP: 192.168.122.22
    phase: Running
    podIP: 192.168.192.58
    podIPs:
    - ip: 192.168.192.58
    qosClass: BestEffort
    startTime: "2020-06-15T06:26:30Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cni.projectcalico.org/podIP: 192.168.192.61/32
    creationTimestamp: "2020-06-15T06:26:30Z"
    generateName: webserver-674cc76668-
    labels:
      app: nginx
      pod-template-hash: 674cc76668
    name: webserver-674cc76668-8sltg
    namespace: default
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: webserver-674cc76668
      uid: 9c146749-aed1-4ef7-a7d5-66b134689ca7
    resourceVersion: "17996881"
    selfLink: /api/v1/namespaces/default/pods/webserver-674cc76668-8sltg
    uid: 30afc447-b260-41e1-be98-4d392859ed63
  spec:
    containers:
    - image: nginx
      imagePullPolicy: Always
      name: nginx
      ports:
      - containerPort: 80
        protocol: TCP
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: default-token-fh8hd
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: hk8s-worker2
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: default-token-fh8hd
      secret:
        defaultMode: 420
        secretName: default-token-fh8hd
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2020-06-15T06:26:30Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2020-06-17T05:57:18Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2020-06-17T05:57:18Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2020-06-15T06:26:30Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://b9afecb8e59708eed83ced69d059ac21f0ed0851290e9b395ce65c7684e2c437
      image: nginx:latest
      imageID: docker-pullable://nginx@sha256:21f32f6c08406306d822a0e6e8b7dc81f53f336570e852e25fbe1e3e3d0d0133
      lastState:
        terminated:
          containerID: docker://d93600dce8ecee085145114ad666454010c1f5579b2e82115bd0c7e0b48da018
          exitCode: 0
          finishedAt: "2020-06-16T02:18:30Z"
          reason: Completed
          startedAt: "2020-06-15T06:26:46Z"
      name: nginx
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2020-06-17T05:57:15Z"
    hostIP: 192.168.122.22
    phase: Running
    podIP: 192.168.192.61
    podIPs:
    - ip: 192.168.192.61
    qosClass: BestEffort
    startTime: "2020-06-15T06:26:30Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cni.projectcalico.org/podIP: 192.168.80.104/32
    creationTimestamp: "2020-06-15T06:26:30Z"
    generateName: webserver-674cc76668-
    labels:
      app: nginx
      pod-template-hash: 674cc76668
    name: webserver-674cc76668-prccg
    namespace: default
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: webserver-674cc76668
      uid: 9c146749-aed1-4ef7-a7d5-66b134689ca7
    resourceVersion: "17996814"
    selfLink: /api/v1/namespaces/default/pods/webserver-674cc76668-prccg
    uid: 227984fe-eb5a-43a1-bdca-514c5ac9885d
  spec:
    containers:
    - image: nginx
      imagePullPolicy: Always
      name: nginx
      ports:
      - containerPort: 80
        protocol: TCP
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: default-token-fh8hd
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: hk8s-worker1
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: default-token-fh8hd
      secret:
        defaultMode: 420
        secretName: default-token-fh8hd
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2020-06-15T06:26:30Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2020-06-17T05:57:08Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2020-06-17T05:57:08Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2020-06-15T06:26:30Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://dac9c9db897927e023ed5e1f9711d16014b19c415c8ffcd23f2be6528a9c553b
      image: nginx:latest
      imageID: docker-pullable://nginx@sha256:21f32f6c08406306d822a0e6e8b7dc81f53f336570e852e25fbe1e3e3d0d0133
      lastState:
        terminated:
          containerID: docker://9a1ae595568bd37377b0f310bea0d53c7763fc92556627a57bc5c8a2f5c44995
          exitCode: 0
          finishedAt: "2020-06-16T02:18:26Z"
          reason: Completed
          startedAt: "2020-06-15T06:26:48Z"
      name: nginx
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2020-06-17T05:57:05Z"
    hostIP: 192.168.122.21
    phase: Running
    podIP: 192.168.80.104
    podIPs:
    - ip: 192.168.80.104
    qosClass: BestEffort
    startTime: "2020-06-15T06:26:30Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cni.projectcalico.org/podIP: 192.168.80.111/32
    creationTimestamp: "2020-06-15T08:45:06Z"
    generateName: baz-deploy-7456c86698-
    labels:
      app: baz-deploy
      exam: cpu-utilizer
      pod-template-hash: 7456c86698
    name: baz-deploy-7456c86698-ct7bx
    namespace: development
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: baz-deploy-7456c86698
      uid: 1610a420-d540-46c1-b30f-3abccca8af7c
    resourceVersion: "17996836"
    selfLink: /api/v1/namespaces/development/pods/baz-deploy-7456c86698-ct7bx
    uid: 781fa1a3-a6cd-427d-b76a-2826cae92a5d
  spec:
    containers:
    - image: k8s.gcr.io/hpa-example
      imagePullPolicy: Always
      name: baz-deploy
      ports:
      - containerPort: 80
        protocol: TCP
      resources:
        limits:
          cpu: 100m
        requests:
          cpu: 100m
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: default-token-hrl8k
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: hk8s-worker1
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: default-token-hrl8k
      secret:
        defaultMode: 420
        secretName: default-token-hrl8k
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2020-06-15T08:45:06Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2020-06-17T05:57:10Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2020-06-17T05:57:10Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2020-06-15T08:45:06Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://0c1f26a6a5924c0a970b3c1960005dfa8d9aa5189bc532af27010b2793bab923
      image: k8s.gcr.io/hpa-example:latest
      imageID: docker-pullable://k8s.gcr.io/hpa-example@sha256:581697a37f0e136db86d6b30392f0db40ce99c8248a7044c770012f4e8491544
      lastState:
        terminated:
          containerID: docker://db8f1c9cab466c42ab3954ccde0f53b4bb8e3d9ae5d2d1669cb7fc98ca95460f
          exitCode: 0
          finishedAt: "2020-06-16T02:18:26Z"
          reason: Completed
          startedAt: "2020-06-15T08:45:12Z"
      name: baz-deploy
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2020-06-17T05:57:08Z"
    hostIP: 192.168.122.21
    phase: Running
    podIP: 192.168.80.111
    podIPs:
    - ip: 192.168.80.111
    qosClass: Burstable
    startTime: "2020-06-15T08:45:06Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cni.projectcalico.org/podIP: 192.168.192.60/32
    creationTimestamp: "2020-06-15T08:45:06Z"
    generateName: baz-deploy-7456c86698-
    labels:
      app: baz-deploy
      exam: cpu-utilizer
      pod-template-hash: 7456c86698
    name: baz-deploy-7456c86698-lf8fd
    namespace: development
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: baz-deploy-7456c86698
      uid: 1610a420-d540-46c1-b30f-3abccca8af7c
    resourceVersion: "17996878"
    selfLink: /api/v1/namespaces/development/pods/baz-deploy-7456c86698-lf8fd
    uid: 1cbb2449-d6eb-4399-be6f-4ecde223823d
  spec:
    containers:
    - image: k8s.gcr.io/hpa-example
      imagePullPolicy: Always
      name: baz-deploy
      ports:
      - containerPort: 80
        protocol: TCP
      resources:
        limits:
          cpu: 100m
        requests:
          cpu: 100m
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: default-token-hrl8k
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: hk8s-worker2
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: default-token-hrl8k
      secret:
        defaultMode: 420
        secretName: default-token-hrl8k
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2020-06-15T08:45:06Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2020-06-17T05:57:18Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2020-06-17T05:57:18Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2020-06-15T08:45:06Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://21baf1d22f072d8aaabb7d50acfacf249e0e9adae3a61767979c12dda22a038d
      image: k8s.gcr.io/hpa-example:latest
      imageID: docker-pullable://k8s.gcr.io/hpa-example@sha256:581697a37f0e136db86d6b30392f0db40ce99c8248a7044c770012f4e8491544
      lastState:
        terminated:
          containerID: docker://35c2a164ac15886759be743a9cd3e2d92d977ee3e38b470d875b6ba3ecb19565
          exitCode: 0
          finishedAt: "2020-06-16T02:18:34Z"
          reason: Completed
          startedAt: "2020-06-15T08:45:13Z"
      name: baz-deploy
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2020-06-17T05:57:14Z"
    hostIP: 192.168.122.22
    phase: Running
    podIP: 192.168.192.60
    podIPs:
    - ip: 192.168.192.60
    qosClass: Burstable
    startTime: "2020-06-15T08:45:06Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cni.projectcalico.org/podIP: 192.168.80.81/32
    creationTimestamp: "2020-06-15T08:45:06Z"
    generateName: baz-deploy-7456c86698-
    labels:
      app: baz-deploy
      exam: cpu-utilizer
      pod-template-hash: 7456c86698
    name: baz-deploy-7456c86698-m6j2j
    namespace: development
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: baz-deploy-7456c86698
      uid: 1610a420-d540-46c1-b30f-3abccca8af7c
    resourceVersion: "17996830"
    selfLink: /api/v1/namespaces/development/pods/baz-deploy-7456c86698-m6j2j
    uid: 6b6fc0c8-9c6f-4b6d-8026-03a76dfc39ba
  spec:
    containers:
    - image: k8s.gcr.io/hpa-example
      imagePullPolicy: Always
      name: baz-deploy
      ports:
      - containerPort: 80
        protocol: TCP
      resources:
        limits:
          cpu: 100m
        requests:
          cpu: 100m
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: default-token-hrl8k
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: hk8s-worker1
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: default-token-hrl8k
      secret:
        defaultMode: 420
        secretName: default-token-hrl8k
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2020-06-15T08:45:06Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2020-06-17T05:57:10Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2020-06-17T05:57:10Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2020-06-15T08:45:06Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://4ec92f39e60dbbfb866ed46dee33b11afd68b0666a35cdd9de9dc5294fae59b6
      image: k8s.gcr.io/hpa-example:latest
      imageID: docker-pullable://k8s.gcr.io/hpa-example@sha256:581697a37f0e136db86d6b30392f0db40ce99c8248a7044c770012f4e8491544
      lastState:
        terminated:
          containerID: docker://fee57ab003a5a6c362c98fbb24b99dd62add0d2cc7c50c617e65f9d575385143
          exitCode: 0
          finishedAt: "2020-06-16T02:18:26Z"
          reason: Completed
          startedAt: "2020-06-15T08:45:12Z"
      name: baz-deploy
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2020-06-17T05:57:08Z"
    hostIP: 192.168.122.21
    phase: Running
    podIP: 192.168.80.81
    podIPs:
    - ip: 192.168.80.81
    qosClass: Burstable
    startTime: "2020-06-15T08:45:06Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cni.projectcalico.org/podIP: 192.168.192.57/32
    creationTimestamp: "2020-06-15T08:45:06Z"
    generateName: baz-deploy-7456c86698-
    labels:
      app: baz-deploy
      exam: cpu-utilizer
      pod-template-hash: 7456c86698
    name: baz-deploy-7456c86698-nn9ln
    namespace: development
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: baz-deploy-7456c86698
      uid: 1610a420-d540-46c1-b30f-3abccca8af7c
    resourceVersion: "17996864"
    selfLink: /api/v1/namespaces/development/pods/baz-deploy-7456c86698-nn9ln
    uid: c23b6ab1-d4b2-4572-9ead-1ce0f91375af
  spec:
    containers:
    - image: k8s.gcr.io/hpa-example
      imagePullPolicy: Always
      name: baz-deploy
      ports:
      - containerPort: 80
        protocol: TCP
      resources:
        limits:
          cpu: 100m
        requests:
          cpu: 100m
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: default-token-hrl8k
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: hk8s-worker2
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: default-token-hrl8k
      secret:
        defaultMode: 420
        secretName: default-token-hrl8k
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2020-06-15T08:45:06Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2020-06-17T05:57:14Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2020-06-17T05:57:14Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2020-06-15T08:45:06Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://ee6b45c458d03806c729bb2e87bc0f735b90fb01cd93ccb027476b7da06c7207
      image: k8s.gcr.io/hpa-example:latest
      imageID: docker-pullable://k8s.gcr.io/hpa-example@sha256:581697a37f0e136db86d6b30392f0db40ce99c8248a7044c770012f4e8491544
      lastState:
        terminated:
          containerID: docker://7b15b701ab5dbd35dc1de02899ec5265bcfc2dc701f5e96754efda531cbc4244
          exitCode: 0
          finishedAt: "2020-06-16T02:18:34Z"
          reason: Completed
          startedAt: "2020-06-15T08:45:13Z"
      name: baz-deploy
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2020-06-17T05:57:04Z"
    hostIP: 192.168.122.22
    phase: Running
    podIP: 192.168.192.57
    podIPs:
    - ip: 192.168.192.57
    qosClass: Burstable
    startTime: "2020-06-15T08:45:06Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cni.projectcalico.org/podIP: 192.168.192.63/32
    creationTimestamp: "2020-06-15T08:45:06Z"
    generateName: load-generator-7d9c4dd7b9-
    labels:
      exam: cpu-utilizer
      pod-template-hash: 7d9c4dd7b9
    name: load-generator-7d9c4dd7b9-mtfm7
    namespace: development
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: load-generator-7d9c4dd7b9
      uid: fdebc091-13f4-4c04-98a1-d73c3c721783
    resourceVersion: "17996891"
    selfLink: /api/v1/namespaces/development/pods/load-generator-7d9c4dd7b9-mtfm7
    uid: 7c7a61df-0b3f-493f-991e-b5cbb47f74f3
  spec:
    containers:
    - args:
      - sh
      - -c
      - while true; do date && sleep 500; done
      image: busybox
      imagePullPolicy: Always
      name: load-generator
      resources:
        limits:
          cpu: 250m
        requests:
          cpu: 250m
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: default-token-hrl8k
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: hk8s-worker2
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: default-token-hrl8k
      secret:
        defaultMode: 420
        secretName: default-token-hrl8k
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2020-06-15T08:45:06Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2020-06-17T05:57:19Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2020-06-17T05:57:19Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2020-06-15T08:45:06Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://62082818abd2d6621108101edac4b457f8ac7e2591162c4cf4afb2b5ee794d0d
      image: busybox:latest
      imageID: docker-pullable://busybox@sha256:95cf004f559831017cdf4628aaf1bb30133677be8702a8c5f2994629f637a209
      lastState:
        terminated:
          containerID: docker://958416e2023b829f8984c03f31598cb253c952319780ab556c28373680fb58cd
          exitCode: 255
          finishedAt: "2020-06-17T05:53:40Z"
          reason: Error
          startedAt: "2020-06-15T08:45:16Z"
      name: load-generator
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2020-06-17T05:57:17Z"
    hostIP: 192.168.122.22
    phase: Running
    podIP: 192.168.192.63
    podIPs:
    - ip: 192.168.192.63
    qosClass: Burstable
    startTime: "2020-06-15T08:45:06Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cni.projectcalico.org/podIP: 192.168.10.24/32
      scheduler.alpha.kubernetes.io/critical-pod: ""
    creationTimestamp: "2020-01-05T07:49:20Z"
    generateName: calico-kube-controllers-778676476b-
    labels:
      k8s-app: calico-kube-controllers
      pod-template-hash: 778676476b
    name: calico-kube-controllers-778676476b-5k2j5
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: calico-kube-controllers-778676476b
      uid: 6ffc1ee8-5317-4e72-8bf1-b794ffef2303
    resourceVersion: "17996894"
    selfLink: /api/v1/namespaces/kube-system/pods/calico-kube-controllers-778676476b-5k2j5
    uid: 66178f4a-c419-4bfb-8742-50bd9affbec5
  spec:
    containers:
    - env:
      - name: ENABLED_CONTROLLERS
        value: node
      - name: DATASTORE_TYPE
        value: kubernetes
      image: calico/kube-controllers:v3.8.5
      imagePullPolicy: IfNotPresent
      name: calico-kube-controllers
      readinessProbe:
        exec:
          command:
          - /usr/bin/check-status
          - -r
        failureThreshold: 3
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: calico-kube-controllers-token-952ct
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: hk8s-master
    nodeSelector:
      beta.kubernetes.io/os: linux
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: calico-kube-controllers
    serviceAccountName: calico-kube-controllers
    terminationGracePeriodSeconds: 30
    tolerations:
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: calico-kube-controllers-token-952ct
      secret:
        defaultMode: 420
        secretName: calico-kube-controllers-token-952ct
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2020-01-05T07:49:53Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2020-06-17T05:57:20Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2020-06-17T05:57:20Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2020-01-05T07:49:53Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://3d5ab5d809e8dafc3353064ef942da6fcf1e1a850d54d4505a63e744072e3621
      image: calico/kube-controllers:v3.8.5
      imageID: docker-pullable://calico/kube-controllers@sha256:5c43ce70ce4324184dd87a9295b750418c6a655c4b01d75b6891fbfc4ac57e93
      lastState:
        terminated:
          containerID: docker://241e39445af3d8f40613ab48c4c99f5e2f7112da9c1342e0eabdd39c20808f97
          exitCode: 2
          finishedAt: "2020-06-16T02:19:11Z"
          reason: Error
          startedAt: "2020-06-08T09:48:17Z"
      name: calico-kube-controllers
      ready: true
      restartCount: 7
      started: true
      state:
        running:
          startedAt: "2020-06-17T05:57:15Z"
    hostIP: 192.168.122.20
    phase: Running
    podIP: 192.168.10.24
    podIPs:
    - ip: 192.168.10.24
    qosClass: BestEffort
    startTime: "2020-01-05T07:49:53Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      scheduler.alpha.kubernetes.io/critical-pod: ""
    creationTimestamp: "2020-06-03T06:50:43Z"
    generateName: calico-node-
    labels:
      controller-revision-hash: d4f766d7
      k8s-app: calico-node
      pod-template-generation: "1"
    name: calico-node-dq6tx
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: calico-node
      uid: 60bfc45f-5da3-4adb-931a-6bce09e86f77
    resourceVersion: "17911403"
    selfLink: /api/v1/namespaces/kube-system/pods/calico-node-dq6tx
    uid: 306e39de-1997-4e97-af41-9bb6d397ca79
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - hk8s-worker3
    containers:
    - env:
      - name: DATASTORE_TYPE
        value: kubernetes
      - name: WAIT_FOR_DATASTORE
        value: "true"
      - name: NODENAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      - name: CALICO_NETWORKING_BACKEND
        valueFrom:
          configMapKeyRef:
            key: calico_backend
            name: calico-config
      - name: CLUSTER_TYPE
        value: k8s,bgp
      - name: IP
        value: autodetect
      - name: CALICO_IPV4POOL_IPIP
        value: Always
      - name: FELIX_IPINIPMTU
        valueFrom:
          configMapKeyRef:
            key: veth_mtu
            name: calico-config
      - name: CALICO_IPV4POOL_CIDR
        value: 192.168.0.0/16
      - name: CALICO_DISABLE_FILE_LOGGING
        value: "true"
      - name: FELIX_DEFAULTENDPOINTTOHOSTACTION
        value: ACCEPT
      - name: FELIX_IPV6SUPPORT
        value: "false"
      - name: FELIX_LOGSEVERITYSCREEN
        value: info
      - name: FELIX_HEALTHENABLED
        value: "true"
      image: calico/node:v3.8.5
      imagePullPolicy: IfNotPresent
      livenessProbe:
        exec:
          command:
          - /bin/calico-node
          - -felix-live
          - -bird-live
        failureThreshold: 6
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      name: calico-node
      readinessProbe:
        exec:
          command:
          - /bin/calico-node
          - -bird-ready
          - -felix-ready
        failureThreshold: 3
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        requests:
          cpu: 250m
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /lib/modules
        name: lib-modules
        readOnly: true
      - mountPath: /run/xtables.lock
        name: xtables-lock
      - mountPath: /var/run/calico
        name: var-run-calico
      - mountPath: /var/lib/calico
        name: var-lib-calico
      - mountPath: /var/run/nodeagent
        name: policysync
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: calico-node-token-scv8z
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    initContainers:
    - command:
      - /opt/cni/bin/calico-ipam
      - -upgrade
      env:
      - name: KUBERNETES_NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      - name: CALICO_NETWORKING_BACKEND
        valueFrom:
          configMapKeyRef:
            key: calico_backend
            name: calico-config
      image: calico/cni:v3.8.5
      imagePullPolicy: IfNotPresent
      name: upgrade-ipam
      resources: {}
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/lib/cni/networks
        name: host-local-net-dir
      - mountPath: /host/opt/cni/bin
        name: cni-bin-dir
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: calico-node-token-scv8z
        readOnly: true
    - command:
      - /install-cni.sh
      env:
      - name: CNI_CONF_NAME
        value: 10-calico.conflist
      - name: CNI_NETWORK_CONFIG
        valueFrom:
          configMapKeyRef:
            key: cni_network_config
            name: calico-config
      - name: KUBERNETES_NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      - name: CNI_MTU
        valueFrom:
          configMapKeyRef:
            key: veth_mtu
            name: calico-config
      - name: SLEEP
        value: "false"
      image: calico/cni:v3.8.5
      imagePullPolicy: IfNotPresent
      name: install-cni
      resources: {}
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /host/opt/cni/bin
        name: cni-bin-dir
      - mountPath: /host/etc/cni/net.d
        name: cni-net-dir
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: calico-node-token-scv8z
        readOnly: true
    - image: calico/pod2daemon-flexvol:v3.8.5
      imagePullPolicy: IfNotPresent
      name: flexvol-driver
      resources: {}
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /host/driver
        name: flexvol-driver-host
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: calico-node-token-scv8z
        readOnly: true
    nodeName: hk8s-worker3
    nodeSelector:
      beta.kubernetes.io/os: linux
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: calico-node
    serviceAccountName: calico-node
    terminationGracePeriodSeconds: 0
    tolerations:
    - effect: NoSchedule
      operator: Exists
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoExecute
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - hostPath:
        path: /lib/modules
        type: ""
      name: lib-modules
    - hostPath:
        path: /var/run/calico
        type: ""
      name: var-run-calico
    - hostPath:
        path: /var/lib/calico
        type: ""
      name: var-lib-calico
    - hostPath:
        path: /run/xtables.lock
        type: FileOrCreate
      name: xtables-lock
    - hostPath:
        path: /opt/cni/bin
        type: ""
      name: cni-bin-dir
    - hostPath:
        path: /etc/cni/net.d
        type: ""
      name: cni-net-dir
    - hostPath:
        path: /var/lib/cni/networks
        type: ""
      name: host-local-net-dir
    - hostPath:
        path: /var/run/nodeagent
        type: DirectoryOrCreate
      name: policysync
    - hostPath:
        path: /usr/libexec/kubernetes/kubelet-plugins/volume/exec/nodeagent~uds
        type: DirectoryOrCreate
      name: flexvol-driver-host
    - name: calico-node-token-scv8z
      secret:
        defaultMode: 420
        secretName: calico-node-token-scv8z
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2020-06-15T10:00:46Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2020-06-15T10:02:00Z"
      status: "False"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2020-06-15T10:00:58Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2020-06-03T06:50:43Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://b8f3a31672d2171020ae24a9a0d3ac429674abd40106a98732b62ef14e1b3759
      image: calico/node:v3.8.5
      imageID: docker-pullable://calico/node@sha256:d007d2666c235091fd96e32235fa2a57af13f3c8b8101c0d3e981a377cf4d4ee
      lastState:
        terminated:
          containerID: docker://a14a72f9a2d6271f0ba340e89ed8c6cfa8898dbba7e897346f0d26e0c7b60262
          exitCode: 0
          finishedAt: "2020-06-03T07:11:43Z"
          reason: Completed
          startedAt: "2020-06-03T06:50:49Z"
      name: calico-node
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2020-06-15T10:00:48Z"
    hostIP: 192.168.122.23
    initContainerStatuses:
    - containerID: docker://5c826edad23911f07dbe0dc677f8c2a96281c8f8e05d6f5fd8e7b34916a64923
      image: calico/cni:v3.8.5
      imageID: docker-pullable://calico/cni@sha256:4fd2ab76043e06e2f1340af77821533ace524651d89c83f4aa66be5e272d1b36
      lastState: {}
      name: upgrade-ipam
      ready: true
      restartCount: 1
      state:
        terminated:
          containerID: docker://5c826edad23911f07dbe0dc677f8c2a96281c8f8e05d6f5fd8e7b34916a64923
          exitCode: 0
          finishedAt: "2020-06-15T10:00:42Z"
          reason: Completed
          startedAt: "2020-06-15T10:00:42Z"
    - containerID: docker://cca240f35afddb1b54fd8ddf39c535c5bcb86efa722153c190c039d18a82c151
      image: calico/cni:v3.8.5
      imageID: docker-pullable://calico/cni@sha256:4fd2ab76043e06e2f1340af77821533ace524651d89c83f4aa66be5e272d1b36
      lastState: {}
      name: install-cni
      ready: true
      restartCount: 0
      state:
        terminated:
          containerID: docker://cca240f35afddb1b54fd8ddf39c535c5bcb86efa722153c190c039d18a82c151
          exitCode: 0
          finishedAt: "2020-06-15T10:00:45Z"
          reason: Completed
          startedAt: "2020-06-15T10:00:44Z"
    - containerID: docker://ce140a45cfeaa4dd39b70e02922cd4ec53b11d270d983ec4d41b113ed88a5fc1
      image: calico/pod2daemon-flexvol:v3.8.5
      imageID: docker-pullable://calico/pod2daemon-flexvol@sha256:a7f22766dad8073e6774fd66cf7e505789453153f680578d418419d10701314b
      lastState: {}
      name: flexvol-driver
      ready: true
      restartCount: 0
      state:
        terminated:
          containerID: docker://ce140a45cfeaa4dd39b70e02922cd4ec53b11d270d983ec4d41b113ed88a5fc1
          exitCode: 0
          finishedAt: "2020-06-15T10:00:47Z"
          reason: Completed
          startedAt: "2020-06-15T10:00:47Z"
    phase: Running
    podIP: 192.168.122.23
    podIPs:
    - ip: 192.168.122.23
    qosClass: Burstable
    startTime: "2020-06-03T06:50:43Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      scheduler.alpha.kubernetes.io/critical-pod: ""
    creationTimestamp: "2020-01-05T07:49:20Z"
    generateName: calico-node-
    labels:
      controller-revision-hash: d4f766d7
      k8s-app: calico-node
      pod-template-generation: "1"
    name: calico-node-hv8pj
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: calico-node
      uid: 60bfc45f-5da3-4adb-931a-6bce09e86f77
    resourceVersion: "17996833"
    selfLink: /api/v1/namespaces/kube-system/pods/calico-node-hv8pj
    uid: 912713b3-6454-492e-873f-94f4e7c19536
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - hk8s-master
    containers:
    - env:
      - name: DATASTORE_TYPE
        value: kubernetes
      - name: WAIT_FOR_DATASTORE
        value: "true"
      - name: NODENAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      - name: CALICO_NETWORKING_BACKEND
        valueFrom:
          configMapKeyRef:
            key: calico_backend
            name: calico-config
      - name: CLUSTER_TYPE
        value: k8s,bgp
      - name: IP
        value: autodetect
      - name: CALICO_IPV4POOL_IPIP
        value: Always
      - name: FELIX_IPINIPMTU
        valueFrom:
          configMapKeyRef:
            key: veth_mtu
            name: calico-config
      - name: CALICO_IPV4POOL_CIDR
        value: 192.168.0.0/16
      - name: CALICO_DISABLE_FILE_LOGGING
        value: "true"
      - name: FELIX_DEFAULTENDPOINTTOHOSTACTION
        value: ACCEPT
      - name: FELIX_IPV6SUPPORT
        value: "false"
      - name: FELIX_LOGSEVERITYSCREEN
        value: info
      - name: FELIX_HEALTHENABLED
        value: "true"
      image: calico/node:v3.8.5
      imagePullPolicy: IfNotPresent
      livenessProbe:
        exec:
          command:
          - /bin/calico-node
          - -felix-live
          - -bird-live
        failureThreshold: 6
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      name: calico-node
      readinessProbe:
        exec:
          command:
          - /bin/calico-node
          - -bird-ready
          - -felix-ready
        failureThreshold: 3
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        requests:
          cpu: 250m
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /lib/modules
        name: lib-modules
        readOnly: true
      - mountPath: /run/xtables.lock
        name: xtables-lock
      - mountPath: /var/run/calico
        name: var-run-calico
      - mountPath: /var/lib/calico
        name: var-lib-calico
      - mountPath: /var/run/nodeagent
        name: policysync
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: calico-node-token-scv8z
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    initContainers:
    - command:
      - /opt/cni/bin/calico-ipam
      - -upgrade
      env:
      - name: KUBERNETES_NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      - name: CALICO_NETWORKING_BACKEND
        valueFrom:
          configMapKeyRef:
            key: calico_backend
            name: calico-config
      image: calico/cni:v3.8.5
      imagePullPolicy: IfNotPresent
      name: upgrade-ipam
      resources: {}
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/lib/cni/networks
        name: host-local-net-dir
      - mountPath: /host/opt/cni/bin
        name: cni-bin-dir
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: calico-node-token-scv8z
        readOnly: true
    - command:
      - /install-cni.sh
      env:
      - name: CNI_CONF_NAME
        value: 10-calico.conflist
      - name: CNI_NETWORK_CONFIG
        valueFrom:
          configMapKeyRef:
            key: cni_network_config
            name: calico-config
      - name: KUBERNETES_NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      - name: CNI_MTU
        valueFrom:
          configMapKeyRef:
            key: veth_mtu
            name: calico-config
      - name: SLEEP
        value: "false"
      image: calico/cni:v3.8.5
      imagePullPolicy: IfNotPresent
      name: install-cni
      resources: {}
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /host/opt/cni/bin
        name: cni-bin-dir
      - mountPath: /host/etc/cni/net.d
        name: cni-net-dir
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: calico-node-token-scv8z
        readOnly: true
    - image: calico/pod2daemon-flexvol:v3.8.5
      imagePullPolicy: IfNotPresent
      name: flexvol-driver
      resources: {}
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /host/driver
        name: flexvol-driver-host
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: calico-node-token-scv8z
        readOnly: true
    nodeName: hk8s-master
    nodeSelector:
      beta.kubernetes.io/os: linux
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: calico-node
    serviceAccountName: calico-node
    terminationGracePeriodSeconds: 0
    tolerations:
    - effect: NoSchedule
      operator: Exists
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoExecute
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - hostPath:
        path: /lib/modules
        type: ""
      name: lib-modules
    - hostPath:
        path: /var/run/calico
        type: ""
      name: var-run-calico
    - hostPath:
        path: /var/lib/calico
        type: ""
      name: var-lib-calico
    - hostPath:
        path: /run/xtables.lock
        type: FileOrCreate
      name: xtables-lock
    - hostPath:
        path: /opt/cni/bin
        type: ""
      name: cni-bin-dir
    - hostPath:
        path: /etc/cni/net.d
        type: ""
      name: cni-net-dir
    - hostPath:
        path: /var/lib/cni/networks
        type: ""
      name: host-local-net-dir
    - hostPath:
        path: /var/run/nodeagent
        type: DirectoryOrCreate
      name: policysync
    - hostPath:
        path: /usr/libexec/kubernetes/kubelet-plugins/volume/exec/nodeagent~uds
        type: DirectoryOrCreate
      name: flexvol-driver-host
    - name: calico-node-token-scv8z
      secret:
        defaultMode: 420
        secretName: calico-node-token-scv8z
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2020-06-17T05:56:18Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2020-06-17T05:57:10Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2020-06-17T05:57:10Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2020-01-05T07:49:20Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://edd07064cb5621a7e635ceaaf0f4e03c0d139f6350b61f43c3da95f673fde7d8
      image: calico/node:v3.8.5
      imageID: docker-pullable://calico/node@sha256:d007d2666c235091fd96e32235fa2a57af13f3c8b8101c0d3e981a377cf4d4ee
      lastState:
        terminated:
          containerID: docker://08501f2ad0b05fbaa3306a341b056cd66663d2e3bf087d52b3b82ed6bc2783b8
          exitCode: 0
          finishedAt: "2020-06-16T02:19:11Z"
          reason: Completed
          startedAt: "2020-06-08T09:48:02Z"
      name: calico-node
      ready: true
      restartCount: 11
      started: true
      state:
        running:
          startedAt: "2020-06-17T05:56:27Z"
    hostIP: 192.168.122.20
    initContainerStatuses:
    - containerID: docker://c85c6616b673bbe05bd9767140874494e3789a8d138d7080785da7aed718d373
      image: calico/cni:v3.8.5
      imageID: docker-pullable://calico/cni@sha256:4fd2ab76043e06e2f1340af77821533ace524651d89c83f4aa66be5e272d1b36
      lastState: {}
      name: upgrade-ipam
      ready: true
      restartCount: 7
      state:
        terminated:
          containerID: docker://c85c6616b673bbe05bd9767140874494e3789a8d138d7080785da7aed718d373
          exitCode: 0
          finishedAt: "2020-06-17T05:56:02Z"
          reason: Completed
          startedAt: "2020-06-17T05:56:00Z"
    - containerID: docker://553192bf97a2a38f31b5aae19de3358b1d830ff5fd9e9a738814c57c79f3d44a
      image: calico/cni:v3.8.5
      imageID: docker-pullable://calico/cni@sha256:4fd2ab76043e06e2f1340af77821533ace524651d89c83f4aa66be5e272d1b36
      lastState: {}
      name: install-cni
      ready: true
      restartCount: 0
      state:
        terminated:
          containerID: docker://553192bf97a2a38f31b5aae19de3358b1d830ff5fd9e9a738814c57c79f3d44a
          exitCode: 0
          finishedAt: "2020-06-17T05:56:14Z"
          reason: Completed
          startedAt: "2020-06-17T05:56:08Z"
    - containerID: docker://32902c23bcd17487fe107e40efd8ff08e3879c8ceeca83de9b7cfe953c71535c
      image: calico/pod2daemon-flexvol:v3.8.5
      imageID: docker-pullable://calico/pod2daemon-flexvol@sha256:a7f22766dad8073e6774fd66cf7e505789453153f680578d418419d10701314b
      lastState: {}
      name: flexvol-driver
      ready: true
      restartCount: 0
      state:
        terminated:
          containerID: docker://32902c23bcd17487fe107e40efd8ff08e3879c8ceeca83de9b7cfe953c71535c
          exitCode: 0
          finishedAt: "2020-06-17T05:56:21Z"
          reason: Completed
          startedAt: "2020-06-17T05:56:21Z"
    phase: Running
    podIP: 192.168.122.20
    podIPs:
    - ip: 192.168.122.20
    qosClass: Burstable
    startTime: "2020-01-05T07:49:20Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      scheduler.alpha.kubernetes.io/critical-pod: ""
    creationTimestamp: "2020-01-05T07:57:34Z"
    generateName: calico-node-
    labels:
      controller-revision-hash: d4f766d7
      k8s-app: calico-node
      pod-template-generation: "1"
    name: calico-node-ktklh
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: calico-node
      uid: 60bfc45f-5da3-4adb-931a-6bce09e86f77
    resourceVersion: "17996633"
    selfLink: /api/v1/namespaces/kube-system/pods/calico-node-ktklh
    uid: fc2aa83d-ccd3-4cae-a6e0-bf1d120d004e
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - hk8s-worker1
    containers:
    - env:
      - name: DATASTORE_TYPE
        value: kubernetes
      - name: WAIT_FOR_DATASTORE
        value: "true"
      - name: NODENAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      - name: CALICO_NETWORKING_BACKEND
        valueFrom:
          configMapKeyRef:
            key: calico_backend
            name: calico-config
      - name: CLUSTER_TYPE
        value: k8s,bgp
      - name: IP
        value: autodetect
      - name: CALICO_IPV4POOL_IPIP
        value: Always
      - name: FELIX_IPINIPMTU
        valueFrom:
          configMapKeyRef:
            key: veth_mtu
            name: calico-config
      - name: CALICO_IPV4POOL_CIDR
        value: 192.168.0.0/16
      - name: CALICO_DISABLE_FILE_LOGGING
        value: "true"
      - name: FELIX_DEFAULTENDPOINTTOHOSTACTION
        value: ACCEPT
      - name: FELIX_IPV6SUPPORT
        value: "false"
      - name: FELIX_LOGSEVERITYSCREEN
        value: info
      - name: FELIX_HEALTHENABLED
        value: "true"
      image: calico/node:v3.8.5
      imagePullPolicy: IfNotPresent
      livenessProbe:
        exec:
          command:
          - /bin/calico-node
          - -felix-live
          - -bird-live
        failureThreshold: 6
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      name: calico-node
      readinessProbe:
        exec:
          command:
          - /bin/calico-node
          - -bird-ready
          - -felix-ready
        failureThreshold: 3
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        requests:
          cpu: 250m
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /lib/modules
        name: lib-modules
        readOnly: true
      - mountPath: /run/xtables.lock
        name: xtables-lock
      - mountPath: /var/run/calico
        name: var-run-calico
      - mountPath: /var/lib/calico
        name: var-lib-calico
      - mountPath: /var/run/nodeagent
        name: policysync
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: calico-node-token-scv8z
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    initContainers:
    - command:
      - /opt/cni/bin/calico-ipam
      - -upgrade
      env:
      - name: KUBERNETES_NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      - name: CALICO_NETWORKING_BACKEND
        valueFrom:
          configMapKeyRef:
            key: calico_backend
            name: calico-config
      image: calico/cni:v3.8.5
      imagePullPolicy: IfNotPresent
      name: upgrade-ipam
      resources: {}
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/lib/cni/networks
        name: host-local-net-dir
      - mountPath: /host/opt/cni/bin
        name: cni-bin-dir
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: calico-node-token-scv8z
        readOnly: true
    - command:
      - /install-cni.sh
      env:
      - name: CNI_CONF_NAME
        value: 10-calico.conflist
      - name: CNI_NETWORK_CONFIG
        valueFrom:
          configMapKeyRef:
            key: cni_network_config
            name: calico-config
      - name: KUBERNETES_NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      - name: CNI_MTU
        valueFrom:
          configMapKeyRef:
            key: veth_mtu
            name: calico-config
      - name: SLEEP
        value: "false"
      image: calico/cni:v3.8.5
      imagePullPolicy: IfNotPresent
      name: install-cni
      resources: {}
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /host/opt/cni/bin
        name: cni-bin-dir
      - mountPath: /host/etc/cni/net.d
        name: cni-net-dir
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: calico-node-token-scv8z
        readOnly: true
    - image: calico/pod2daemon-flexvol:v3.8.5
      imagePullPolicy: IfNotPresent
      name: flexvol-driver
      resources: {}
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /host/driver
        name: flexvol-driver-host
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: calico-node-token-scv8z
        readOnly: true
    nodeName: hk8s-worker1
    nodeSelector:
      beta.kubernetes.io/os: linux
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: calico-node
    serviceAccountName: calico-node
    terminationGracePeriodSeconds: 0
    tolerations:
    - effect: NoSchedule
      operator: Exists
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoExecute
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - hostPath:
        path: /lib/modules
        type: ""
      name: lib-modules
    - hostPath:
        path: /var/run/calico
        type: ""
      name: var-run-calico
    - hostPath:
        path: /var/lib/calico
        type: ""
      name: var-lib-calico
    - hostPath:
        path: /run/xtables.lock
        type: FileOrCreate
      name: xtables-lock
    - hostPath:
        path: /opt/cni/bin
        type: ""
      name: cni-bin-dir
    - hostPath:
        path: /etc/cni/net.d
        type: ""
      name: cni-net-dir
    - hostPath:
        path: /var/lib/cni/networks
        type: ""
      name: host-local-net-dir
    - hostPath:
        path: /var/run/nodeagent
        type: DirectoryOrCreate
      name: policysync
    - hostPath:
        path: /usr/libexec/kubernetes/kubelet-plugins/volume/exec/nodeagent~uds
        type: DirectoryOrCreate
      name: flexvol-driver-host
    - name: calico-node-token-scv8z
      secret:
        defaultMode: 420
        secretName: calico-node-token-scv8z
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2020-06-17T05:56:00Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2020-06-17T05:56:49Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2020-06-17T05:56:49Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2020-01-05T07:57:34Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://711ce42f293bdd0969ab9e4efaa0fd74c08f1acf8cca475e06db71471ada0505
      image: calico/node:v3.8.5
      imageID: docker-pullable://calico/node@sha256:d007d2666c235091fd96e32235fa2a57af13f3c8b8101c0d3e981a377cf4d4ee
      lastState:
        terminated:
          containerID: docker://1acb2eb66fa8e2552669011e9eaee98f61162ae77b8730b35d265c33bcff462f
          exitCode: 0
          finishedAt: "2020-06-16T02:18:25Z"
          reason: Completed
          startedAt: "2020-06-08T09:48:02Z"
      name: calico-node
      ready: true
      restartCount: 9
      started: true
      state:
        running:
          startedAt: "2020-06-17T05:56:04Z"
    hostIP: 192.168.122.21
    initContainerStatuses:
    - containerID: docker://51d8c0e313d33e6b2ae43ccad6dbf8abd2cfb8029b8bd9e641b843435624d257
      image: calico/cni:v3.8.5
      imageID: docker-pullable://calico/cni@sha256:4fd2ab76043e06e2f1340af77821533ace524651d89c83f4aa66be5e272d1b36
      lastState: {}
      name: upgrade-ipam
      ready: true
      restartCount: 7
      state:
        terminated:
          containerID: docker://51d8c0e313d33e6b2ae43ccad6dbf8abd2cfb8029b8bd9e641b843435624d257
          exitCode: 0
          finishedAt: "2020-06-17T05:55:50Z"
          reason: Completed
          startedAt: "2020-06-17T05:55:49Z"
    - containerID: docker://51ac7b0579ac8398be126ae2d8df1c3daaf4bfd9b1d8e854d9670d81192346c0
      image: calico/cni:v3.8.5
      imageID: docker-pullable://calico/cni@sha256:4fd2ab76043e06e2f1340af77821533ace524651d89c83f4aa66be5e272d1b36
      lastState: {}
      name: install-cni
      ready: true
      restartCount: 0
      state:
        terminated:
          containerID: docker://51ac7b0579ac8398be126ae2d8df1c3daaf4bfd9b1d8e854d9670d81192346c0
          exitCode: 0
          finishedAt: "2020-06-17T05:55:57Z"
          reason: Completed
          startedAt: "2020-06-17T05:55:55Z"
    - containerID: docker://eb38afc8fc797ac545f3cf3317512c9f5fefdbd91425f17958e16cad44a9efaa
      image: calico/pod2daemon-flexvol:v3.8.5
      imageID: docker-pullable://calico/pod2daemon-flexvol@sha256:a7f22766dad8073e6774fd66cf7e505789453153f680578d418419d10701314b
      lastState: {}
      name: flexvol-driver
      ready: true
      restartCount: 0
      state:
        terminated:
          containerID: docker://eb38afc8fc797ac545f3cf3317512c9f5fefdbd91425f17958e16cad44a9efaa
          exitCode: 0
          finishedAt: "2020-06-17T05:56:01Z"
          reason: Completed
          startedAt: "2020-06-17T05:56:01Z"
    phase: Running
    podIP: 192.168.122.21
    podIPs:
    - ip: 192.168.122.21
    qosClass: Burstable
    startTime: "2020-01-05T07:57:34Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      scheduler.alpha.kubernetes.io/critical-pod: ""
    creationTimestamp: "2020-06-03T03:51:04Z"
    generateName: calico-node-
    labels:
      controller-revision-hash: d4f766d7
      k8s-app: calico-node
      pod-template-generation: "1"
    name: calico-node-mzctr
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: calico-node
      uid: 60bfc45f-5da3-4adb-931a-6bce09e86f77
    resourceVersion: "17996656"
    selfLink: /api/v1/namespaces/kube-system/pods/calico-node-mzctr
    uid: 9c3aede0-5d5a-4071-ba97-987f4528b512
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - hk8s-worker2
    containers:
    - env:
      - name: DATASTORE_TYPE
        value: kubernetes
      - name: WAIT_FOR_DATASTORE
        value: "true"
      - name: NODENAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      - name: CALICO_NETWORKING_BACKEND
        valueFrom:
          configMapKeyRef:
            key: calico_backend
            name: calico-config
      - name: CLUSTER_TYPE
        value: k8s,bgp
      - name: IP
        value: autodetect
      - name: CALICO_IPV4POOL_IPIP
        value: Always
      - name: FELIX_IPINIPMTU
        valueFrom:
          configMapKeyRef:
            key: veth_mtu
            name: calico-config
      - name: CALICO_IPV4POOL_CIDR
        value: 192.168.0.0/16
      - name: CALICO_DISABLE_FILE_LOGGING
        value: "true"
      - name: FELIX_DEFAULTENDPOINTTOHOSTACTION
        value: ACCEPT
      - name: FELIX_IPV6SUPPORT
        value: "false"
      - name: FELIX_LOGSEVERITYSCREEN
        value: info
      - name: FELIX_HEALTHENABLED
        value: "true"
      image: calico/node:v3.8.5
      imagePullPolicy: IfNotPresent
      livenessProbe:
        exec:
          command:
          - /bin/calico-node
          - -felix-live
          - -bird-live
        failureThreshold: 6
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      name: calico-node
      readinessProbe:
        exec:
          command:
          - /bin/calico-node
          - -bird-ready
          - -felix-ready
        failureThreshold: 3
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        requests:
          cpu: 250m
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /lib/modules
        name: lib-modules
        readOnly: true
      - mountPath: /run/xtables.lock
        name: xtables-lock
      - mountPath: /var/run/calico
        name: var-run-calico
      - mountPath: /var/lib/calico
        name: var-lib-calico
      - mountPath: /var/run/nodeagent
        name: policysync
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: calico-node-token-scv8z
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    initContainers:
    - command:
      - /opt/cni/bin/calico-ipam
      - -upgrade
      env:
      - name: KUBERNETES_NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      - name: CALICO_NETWORKING_BACKEND
        valueFrom:
          configMapKeyRef:
            key: calico_backend
            name: calico-config
      image: calico/cni:v3.8.5
      imagePullPolicy: IfNotPresent
      name: upgrade-ipam
      resources: {}
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/lib/cni/networks
        name: host-local-net-dir
      - mountPath: /host/opt/cni/bin
        name: cni-bin-dir
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: calico-node-token-scv8z
        readOnly: true
    - command:
      - /install-cni.sh
      env:
      - name: CNI_CONF_NAME
        value: 10-calico.conflist
      - name: CNI_NETWORK_CONFIG
        valueFrom:
          configMapKeyRef:
            key: cni_network_config
            name: calico-config
      - name: KUBERNETES_NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      - name: CNI_MTU
        valueFrom:
          configMapKeyRef:
            key: veth_mtu
            name: calico-config
      - name: SLEEP
        value: "false"
      image: calico/cni:v3.8.5
      imagePullPolicy: IfNotPresent
      name: install-cni
      resources: {}
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /host/opt/cni/bin
        name: cni-bin-dir
      - mountPath: /host/etc/cni/net.d
        name: cni-net-dir
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: calico-node-token-scv8z
        readOnly: true
    - image: calico/pod2daemon-flexvol:v3.8.5
      imagePullPolicy: IfNotPresent
      name: flexvol-driver
      resources: {}
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /host/driver
        name: flexvol-driver-host
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: calico-node-token-scv8z
        readOnly: true
    nodeName: hk8s-worker2
    nodeSelector:
      beta.kubernetes.io/os: linux
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: calico-node
    serviceAccountName: calico-node
    terminationGracePeriodSeconds: 0
    tolerations:
    - effect: NoSchedule
      operator: Exists
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoExecute
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - hostPath:
        path: /lib/modules
        type: ""
      name: lib-modules
    - hostPath:
        path: /var/run/calico
        type: ""
      name: var-run-calico
    - hostPath:
        path: /var/lib/calico
        type: ""
      name: var-lib-calico
    - hostPath:
        path: /run/xtables.lock
        type: FileOrCreate
      name: xtables-lock
    - hostPath:
        path: /opt/cni/bin
        type: ""
      name: cni-bin-dir
    - hostPath:
        path: /etc/cni/net.d
        type: ""
      name: cni-net-dir
    - hostPath:
        path: /var/lib/cni/networks
        type: ""
      name: host-local-net-dir
    - hostPath:
        path: /var/run/nodeagent
        type: DirectoryOrCreate
      name: policysync
    - hostPath:
        path: /usr/libexec/kubernetes/kubelet-plugins/volume/exec/nodeagent~uds
        type: DirectoryOrCreate
      name: flexvol-driver-host
    - name: calico-node-token-scv8z
      secret:
        defaultMode: 420
        secretName: calico-node-token-scv8z
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2020-06-17T05:56:01Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2020-06-17T05:56:52Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2020-06-17T05:56:52Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2020-06-03T03:51:04Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://65c8ed656db78ad14dc68b2a9f2a13dfcd71f06d8d0c96edf5f4206c7747703a
      image: calico/node:v3.8.5
      imageID: docker-pullable://calico/node@sha256:d007d2666c235091fd96e32235fa2a57af13f3c8b8101c0d3e981a377cf4d4ee
      lastState:
        terminated:
          containerID: docker://cc5531c65c5b7eea63f217ed7f6e583067c17127ecb6311e6fa2c38c4a47f0e7
          exitCode: 0
          finishedAt: "2020-06-16T02:18:31Z"
          reason: Completed
          startedAt: "2020-06-08T09:47:31Z"
      name: calico-node
      ready: true
      restartCount: 2
      started: true
      state:
        running:
          startedAt: "2020-06-17T05:56:05Z"
    hostIP: 192.168.122.22
    initContainerStatuses:
    - containerID: docker://a04b3ce011931f9c44dc9a732fdeca927b255a47578cb89e5550d90e78bcf0c3
      image: calico/cni:v3.8.5
      imageID: docker-pullable://calico/cni@sha256:4fd2ab76043e06e2f1340af77821533ace524651d89c83f4aa66be5e272d1b36
      lastState: {}
      name: upgrade-ipam
      ready: true
      restartCount: 2
      state:
        terminated:
          containerID: docker://a04b3ce011931f9c44dc9a732fdeca927b255a47578cb89e5550d90e78bcf0c3
          exitCode: 0
          finishedAt: "2020-06-17T05:55:52Z"
          reason: Completed
          startedAt: "2020-06-17T05:55:50Z"
    - containerID: docker://007cead78067de1f67964a4ee2104192d525e5a29f3c0c6925ae4e91a87a7af4
      image: calico/cni:v3.8.5
      imageID: docker-pullable://calico/cni@sha256:4fd2ab76043e06e2f1340af77821533ace524651d89c83f4aa66be5e272d1b36
      lastState: {}
      name: install-cni
      ready: true
      restartCount: 0
      state:
        terminated:
          containerID: docker://007cead78067de1f67964a4ee2104192d525e5a29f3c0c6925ae4e91a87a7af4
          exitCode: 0
          finishedAt: "2020-06-17T05:55:59Z"
          reason: Completed
          startedAt: "2020-06-17T05:55:56Z"
    - containerID: docker://1e410eb79cab4003e413f8f58b787a818738047faa7c141f883e063c0317b66c
      image: calico/pod2daemon-flexvol:v3.8.5
      imageID: docker-pullable://calico/pod2daemon-flexvol@sha256:a7f22766dad8073e6774fd66cf7e505789453153f680578d418419d10701314b
      lastState: {}
      name: flexvol-driver
      ready: true
      restartCount: 0
      state:
        terminated:
          containerID: docker://1e410eb79cab4003e413f8f58b787a818738047faa7c141f883e063c0317b66c
          exitCode: 0
          finishedAt: "2020-06-17T05:56:02Z"
          reason: Completed
          startedAt: "2020-06-17T05:56:02Z"
    phase: Running
    podIP: 192.168.122.22
    podIPs:
    - ip: 192.168.122.22
    qosClass: Burstable
    startTime: "2020-06-03T03:51:05Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cni.projectcalico.org/podIP: 192.168.10.23/32
    creationTimestamp: "2020-01-05T07:46:54Z"
    generateName: coredns-5644d7b6d9-
    labels:
      k8s-app: kube-dns
      pod-template-hash: 5644d7b6d9
    name: coredns-5644d7b6d9-nmdkt
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: coredns-5644d7b6d9
      uid: 7a98bceb-b138-4fd2-b4a9-0f21d2192b3a
    resourceVersion: "17996798"
    selfLink: /api/v1/namespaces/kube-system/pods/coredns-5644d7b6d9-nmdkt
    uid: 2f573d5f-a0a1-4c21-b722-7167e9fd6e8a
  spec:
    containers:
    - args:
      - -conf
      - /etc/coredns/Corefile
      image: k8s.gcr.io/coredns:1.6.2
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 5
        httpGet:
          path: /health
          port: 8080
          scheme: HTTP
        initialDelaySeconds: 60
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      name: coredns
      ports:
      - containerPort: 53
        name: dns
        protocol: UDP
      - containerPort: 53
        name: dns-tcp
        protocol: TCP
      - containerPort: 9153
        name: metrics
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /ready
          port: 8181
          scheme: HTTP
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        limits:
          memory: 170Mi
        requests:
          cpu: 100m
          memory: 70Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          add:
          - NET_BIND_SERVICE
          drop:
          - all
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/coredns
        name: config-volume
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: coredns-token-hxzrx
        readOnly: true
    dnsPolicy: Default
    enableServiceLinks: true
    nodeName: hk8s-master
    nodeSelector:
      beta.kubernetes.io/os: linux
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: coredns
    serviceAccountName: coredns
    terminationGracePeriodSeconds: 30
    tolerations:
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - configMap:
        defaultMode: 420
        items:
        - key: Corefile
          path: Corefile
        name: coredns
      name: config-volume
    - name: coredns-token-hxzrx
      secret:
        defaultMode: 420
        secretName: coredns-token-hxzrx
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2020-01-05T07:49:53Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2020-06-17T05:57:07Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2020-06-17T05:57:07Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2020-01-05T07:49:53Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://2498c9ad229654d8389b8049fd13259b61f125786970e11c53d69456c18932ac
      image: k8s.gcr.io/coredns:1.6.2
      imageID: docker-pullable://k8s.gcr.io/coredns@sha256:12eb885b8685b1b13a04ecf5c23bc809c2e57917252fd7b0be9e9c00644e8ee5
      lastState:
        terminated:
          containerID: docker://6203ec9abc86525ed4935625f1046daa2e4dabc1736d7132cb9e2dd0250cb470
          exitCode: 0
          finishedAt: "2020-06-16T02:19:11Z"
          reason: Completed
          startedAt: "2020-06-08T09:48:03Z"
      name: coredns
      ready: true
      restartCount: 7
      started: true
      state:
        running:
          startedAt: "2020-06-17T05:56:56Z"
    hostIP: 192.168.122.20
    phase: Running
    podIP: 192.168.10.23
    podIPs:
    - ip: 192.168.10.23
    qosClass: Burstable
    startTime: "2020-01-05T07:49:53Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cni.projectcalico.org/podIP: 192.168.10.22/32
    creationTimestamp: "2020-01-05T07:46:54Z"
    generateName: coredns-5644d7b6d9-
    labels:
      k8s-app: kube-dns
      pod-template-hash: 5644d7b6d9
    name: coredns-5644d7b6d9-wt6w9
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: coredns-5644d7b6d9
      uid: 7a98bceb-b138-4fd2-b4a9-0f21d2192b3a
    resourceVersion: "17996782"
    selfLink: /api/v1/namespaces/kube-system/pods/coredns-5644d7b6d9-wt6w9
    uid: a4d45fb8-38fe-4a63-8b38-0aaf1f334637
  spec:
    containers:
    - args:
      - -conf
      - /etc/coredns/Corefile
      image: k8s.gcr.io/coredns:1.6.2
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 5
        httpGet:
          path: /health
          port: 8080
          scheme: HTTP
        initialDelaySeconds: 60
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      name: coredns
      ports:
      - containerPort: 53
        name: dns
        protocol: UDP
      - containerPort: 53
        name: dns-tcp
        protocol: TCP
      - containerPort: 9153
        name: metrics
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /ready
          port: 8181
          scheme: HTTP
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        limits:
          memory: 170Mi
        requests:
          cpu: 100m
          memory: 70Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          add:
          - NET_BIND_SERVICE
          drop:
          - all
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/coredns
        name: config-volume
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: coredns-token-hxzrx
        readOnly: true
    dnsPolicy: Default
    enableServiceLinks: true
    nodeName: hk8s-master
    nodeSelector:
      beta.kubernetes.io/os: linux
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: coredns
    serviceAccountName: coredns
    terminationGracePeriodSeconds: 30
    tolerations:
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - configMap:
        defaultMode: 420
        items:
        - key: Corefile
          path: Corefile
        name: coredns
      name: config-volume
    - name: coredns-token-hxzrx
      secret:
        defaultMode: 420
        secretName: coredns-token-hxzrx
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2020-01-05T07:49:53Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2020-06-17T05:57:05Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2020-06-17T05:57:05Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2020-01-05T07:49:53Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://1b9826b7f6071e67090578b4a17d0db3965541c5ed915a132be7a8c4e0f91ad0
      image: k8s.gcr.io/coredns:1.6.2
      imageID: docker-pullable://k8s.gcr.io/coredns@sha256:12eb885b8685b1b13a04ecf5c23bc809c2e57917252fd7b0be9e9c00644e8ee5
      lastState: {}
      name: coredns
      ready: true
      restartCount: 7
      started: true
      state:
        running:
          startedAt: "2020-06-17T05:56:56Z"
    hostIP: 192.168.122.20
    phase: Running
    podIP: 192.168.10.22
    podIPs:
    - ip: 192.168.10.22
    qosClass: Burstable
    startTime: "2020-01-05T07:49:53Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubernetes.io/config.hash: 79893b206fd71d9ea0bb065e77652019
      kubernetes.io/config.mirror: 79893b206fd71d9ea0bb065e77652019
      kubernetes.io/config.seen: "2020-01-05T07:46:04.567561509Z"
      kubernetes.io/config.source: file
    creationTimestamp: "2020-01-05T07:47:41Z"
    labels:
      component: etcd
      tier: control-plane
    name: etcd-hk8s-master
    namespace: kube-system
    resourceVersion: "17996262"
    selfLink: /api/v1/namespaces/kube-system/pods/etcd-hk8s-master
    uid: 19a474e8-70f6-4f81-b585-68b042bd3419
  spec:
    containers:
    - command:
      - etcd
      - --advertise-client-urls=https://192.168.122.20:2379
      - --cert-file=/etc/kubernetes/pki/etcd/server.crt
      - --client-cert-auth=true
      - --data-dir=/var/lib/etcd
      - --initial-advertise-peer-urls=https://192.168.122.20:2380
      - --initial-cluster=hk8s-master=https://192.168.122.20:2380
      - --key-file=/etc/kubernetes/pki/etcd/server.key
      - --listen-client-urls=https://127.0.0.1:2379,https://192.168.122.20:2379
      - --listen-metrics-urls=http://127.0.0.1:2381
      - --listen-peer-urls=https://192.168.122.20:2380
      - --name=hk8s-master
      - --peer-cert-file=/etc/kubernetes/pki/etcd/peer.crt
      - --peer-client-cert-auth=true
      - --peer-key-file=/etc/kubernetes/pki/etcd/peer.key
      - --peer-trusted-ca-file=/etc/kubernetes/pki/etcd/ca.crt
      - --snapshot-count=10000
      - --trusted-ca-file=/etc/kubernetes/pki/etcd/ca.crt
      image: k8s.gcr.io/etcd:3.3.15-0
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 8
        httpGet:
          host: 127.0.0.1
          path: /health
          port: 2381
          scheme: HTTP
        initialDelaySeconds: 15
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      name: etcd
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/lib/etcd
        name: etcd-data
      - mountPath: /etc/kubernetes/pki/etcd
        name: etcd-certs
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: hk8s-master
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      operator: Exists
    volumes:
    - hostPath:
        path: /etc/kubernetes/pki/etcd
        type: DirectoryOrCreate
      name: etcd-certs
    - hostPath:
        path: /var/lib/etcd
        type: DirectoryOrCreate
      name: etcd-data
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2020-06-17T05:54:23Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2020-06-17T05:54:40Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2020-06-17T05:54:40Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2020-06-17T05:54:23Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://2fdd6ff4866cf0684e83e9c154852cf0ec44438952905a4877c4c35ad04763bb
      image: k8s.gcr.io/etcd:3.3.15-0
      imageID: docker-pullable://k8s.gcr.io/etcd@sha256:12c2c5e5731c3bcd56e6f1c05c0f9198b6f06793fa7fca2fb43aab9622dc4afa
      lastState:
        terminated:
          containerID: docker://dc8cb1ebc967da8485a524f9f5950d121ee3b103da61285f967ff687afe53de7
          exitCode: 0
          finishedAt: "2020-06-16T02:19:11Z"
          reason: Completed
          startedAt: "2020-06-08T09:47:04Z"
      name: etcd
      ready: true
      restartCount: 7
      started: true
      state:
        running:
          startedAt: "2020-06-17T05:54:36Z"
    hostIP: 192.168.122.20
    phase: Running
    podIP: 192.168.122.20
    podIPs:
    - ip: 192.168.122.20
    qosClass: BestEffort
    startTime: "2020-06-17T05:54:23Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubernetes.io/config.hash: 3e6d0c08ac43dcbada13240f3af79a18
      kubernetes.io/config.mirror: 3e6d0c08ac43dcbada13240f3af79a18
      kubernetes.io/config.seen: "2020-01-05T07:46:04.567580403Z"
      kubernetes.io/config.source: file
    creationTimestamp: "2020-01-05T07:47:47Z"
    labels:
      component: kube-apiserver
      tier: control-plane
    name: kube-apiserver-hk8s-master
    namespace: kube-system
    resourceVersion: "17996258"
    selfLink: /api/v1/namespaces/kube-system/pods/kube-apiserver-hk8s-master
    uid: efcebca1-6d6a-4a04-b09e-6ca59ae54911
  spec:
    containers:
    - command:
      - kube-apiserver
      - --advertise-address=192.168.122.20
      - --allow-privileged=true
      - --authorization-mode=Node,RBAC
      - --client-ca-file=/etc/kubernetes/pki/ca.crt
      - --enable-admission-plugins=NodeRestriction
      - --enable-bootstrap-token-auth=true
      - --etcd-cafile=/etc/kubernetes/pki/etcd/ca.crt
      - --etcd-certfile=/etc/kubernetes/pki/apiserver-etcd-client.crt
      - --etcd-keyfile=/etc/kubernetes/pki/apiserver-etcd-client.key
      - --etcd-servers=https://127.0.0.1:2379
      - --insecure-port=0
      - --kubelet-client-certificate=/etc/kubernetes/pki/apiserver-kubelet-client.crt
      - --kubelet-client-key=/etc/kubernetes/pki/apiserver-kubelet-client.key
      - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname
      - --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.crt
      - --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client.key
      - --requestheader-allowed-names=front-proxy-client
      - --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt
      - --requestheader-extra-headers-prefix=X-Remote-Extra-
      - --requestheader-group-headers=X-Remote-Group
      - --requestheader-username-headers=X-Remote-User
      - --secure-port=6443
      - --service-account-key-file=/etc/kubernetes/pki/sa.pub
      - --service-cluster-ip-range=10.96.0.0/12
      - --tls-cert-file=/etc/kubernetes/pki/apiserver.crt
      - --tls-private-key-file=/etc/kubernetes/pki/apiserver.key
      image: k8s.gcr.io/kube-apiserver:v1.16.0
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 8
        httpGet:
          host: 192.168.122.20
          path: /healthz
          port: 6443
          scheme: HTTPS
        initialDelaySeconds: 15
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      name: kube-apiserver
      resources:
        requests:
          cpu: 250m
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/ssl/certs
        name: ca-certs
        readOnly: true
      - mountPath: /etc/ca-certificates
        name: etc-ca-certificates
        readOnly: true
      - mountPath: /etc/kubernetes/pki
        name: k8s-certs
        readOnly: true
      - mountPath: /usr/local/share/ca-certificates
        name: usr-local-share-ca-certificates
        readOnly: true
      - mountPath: /usr/share/ca-certificates
        name: usr-share-ca-certificates
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: hk8s-master
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      operator: Exists
    volumes:
    - hostPath:
        path: /etc/ssl/certs
        type: DirectoryOrCreate
      name: ca-certs
    - hostPath:
        path: /etc/ca-certificates
        type: DirectoryOrCreate
      name: etc-ca-certificates
    - hostPath:
        path: /etc/kubernetes/pki
        type: DirectoryOrCreate
      name: k8s-certs
    - hostPath:
        path: /usr/local/share/ca-certificates
        type: DirectoryOrCreate
      name: usr-local-share-ca-certificates
    - hostPath:
        path: /usr/share/ca-certificates
        type: DirectoryOrCreate
      name: usr-share-ca-certificates
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2020-06-17T05:54:20Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2020-06-17T05:55:00Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2020-06-17T05:55:00Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2020-06-17T05:54:20Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://15df84d5faf9539726c5bbe660713b245de884f2d9180eb380efdaffd88a2a41
      image: k8s.gcr.io/kube-apiserver:v1.16.0
      imageID: docker-pullable://k8s.gcr.io/kube-apiserver@sha256:f4168527c91289da2708f62ae729fdde5fb484167dd05ffbb7ab666f60de96cd
      lastState:
        terminated:
          containerID: docker://e578db77d90d87604638e74465bf4372e460354dc3e26e51b9304f3ab2dbf8bc
          exitCode: 1
          finishedAt: "2020-06-16T02:19:12Z"
          reason: Error
          startedAt: "2020-06-08T09:47:04Z"
      name: kube-apiserver
      ready: true
      restartCount: 10
      started: true
      state:
        running:
          startedAt: "2020-06-17T05:54:58Z"
    hostIP: 192.168.122.20
    phase: Running
    podIP: 192.168.122.20
    podIPs:
    - ip: 192.168.122.20
    qosClass: Burstable
    startTime: "2020-06-17T05:54:20Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubernetes.io/config.hash: 1c5881b372ce5b4428be237201629125
      kubernetes.io/config.mirror: 1c5881b372ce5b4428be237201629125
      kubernetes.io/config.seen: "2020-01-05T07:46:04.567589868Z"
      kubernetes.io/config.source: file
    creationTimestamp: "2020-01-05T07:47:43Z"
    labels:
      component: kube-controller-manager
      tier: control-plane
    name: kube-controller-manager-hk8s-master
    namespace: kube-system
    resourceVersion: "17996231"
    selfLink: /api/v1/namespaces/kube-system/pods/kube-controller-manager-hk8s-master
    uid: 9dbfc96e-a36a-4b41-8fd4-d8b8e7705390
  spec:
    containers:
    - command:
      - kube-controller-manager
      - --allocate-node-cidrs=true
      - --authentication-kubeconfig=/etc/kubernetes/controller-manager.conf
      - --authorization-kubeconfig=/etc/kubernetes/controller-manager.conf
      - --bind-address=127.0.0.1
      - --client-ca-file=/etc/kubernetes/pki/ca.crt
      - --cluster-cidr=192.168.0.0/16
      - --cluster-signing-cert-file=/etc/kubernetes/pki/ca.crt
      - --cluster-signing-key-file=/etc/kubernetes/pki/ca.key
      - --controllers=*,bootstrapsigner,tokencleaner
      - --kubeconfig=/etc/kubernetes/controller-manager.conf
      - --leader-elect=true
      - --node-cidr-mask-size=24
      - --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt
      - --root-ca-file=/etc/kubernetes/pki/ca.crt
      - --service-account-private-key-file=/etc/kubernetes/pki/sa.key
      - --service-cluster-ip-range=10.96.0.0/12
      - --use-service-account-credentials=true
      image: k8s.gcr.io/kube-controller-manager:v1.16.0
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 8
        httpGet:
          host: 127.0.0.1
          path: /healthz
          port: 10252
          scheme: HTTP
        initialDelaySeconds: 15
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      name: kube-controller-manager
      resources:
        requests:
          cpu: 200m
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/ssl/certs
        name: ca-certs
        readOnly: true
      - mountPath: /etc/ca-certificates
        name: etc-ca-certificates
        readOnly: true
      - mountPath: /etc/kubernetes/pki
        name: k8s-certs
        readOnly: true
      - mountPath: /etc/kubernetes/controller-manager.conf
        name: kubeconfig
        readOnly: true
      - mountPath: /usr/local/share/ca-certificates
        name: usr-local-share-ca-certificates
        readOnly: true
      - mountPath: /usr/share/ca-certificates
        name: usr-share-ca-certificates
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: hk8s-master
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      operator: Exists
    volumes:
    - hostPath:
        path: /etc/ssl/certs
        type: DirectoryOrCreate
      name: ca-certs
    - hostPath:
        path: /etc/ca-certificates
        type: DirectoryOrCreate
      name: etc-ca-certificates
    - hostPath:
        path: /etc/kubernetes/pki
        type: DirectoryOrCreate
      name: k8s-certs
    - hostPath:
        path: /etc/kubernetes/controller-manager.conf
        type: FileOrCreate
      name: kubeconfig
    - hostPath:
        path: /usr/local/share/ca-certificates
        type: DirectoryOrCreate
      name: usr-local-share-ca-certificates
    - hostPath:
        path: /usr/share/ca-certificates
        type: DirectoryOrCreate
      name: usr-share-ca-certificates
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2020-06-17T05:54:21Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2020-06-17T05:54:40Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2020-06-17T05:54:40Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2020-06-17T05:54:21Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://b5a137fc771e2d60fe233b0342c2a677ff0152ffdb8e012699713be601504f57
      image: k8s.gcr.io/kube-controller-manager:v1.16.0
      imageID: docker-pullable://k8s.gcr.io/kube-controller-manager@sha256:c156a05ee9d40e3ca2ebf9337f38a10558c1fc6c9124006f128a82e6c38cdf3e
      lastState:
        terminated:
          containerID: docker://3fc39d3f25bf620363d469ceac0e9cb1e21b7d10832ffb81230f85078752b0e1
          exitCode: 2
          finishedAt: "2020-06-16T02:19:12Z"
          reason: Error
          startedAt: "2020-06-08T09:47:04Z"
      name: kube-controller-manager
      ready: true
      restartCount: 12
      started: true
      state:
        running:
          startedAt: "2020-06-17T05:54:36Z"
    hostIP: 192.168.122.20
    phase: Running
    podIP: 192.168.122.20
    podIPs:
    - ip: 192.168.122.20
    qosClass: Burstable
    startTime: "2020-06-17T05:54:21Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2020-06-03T06:50:43Z"
    generateName: kube-proxy-
    labels:
      controller-revision-hash: 68594d95c
      k8s-app: kube-proxy
      pod-template-generation: "1"
    name: kube-proxy-cvhsf
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: kube-proxy
      uid: ce3de9b6-b09b-4e2f-8b76-851ff17ff92f
    resourceVersion: "17911406"
    selfLink: /api/v1/namespaces/kube-system/pods/kube-proxy-cvhsf
    uid: 1016118d-a1de-4df6-96a1-279c67cfd90e
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - hk8s-worker3
    containers:
    - command:
      - /usr/local/bin/kube-proxy
      - --config=/var/lib/kube-proxy/config.conf
      - --hostname-override=$(NODE_NAME)
      env:
      - name: NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      image: k8s.gcr.io/kube-proxy:v1.16.0
      imagePullPolicy: IfNotPresent
      name: kube-proxy
      resources: {}
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/lib/kube-proxy
        name: kube-proxy
      - mountPath: /run/xtables.lock
        name: xtables-lock
      - mountPath: /lib/modules
        name: lib-modules
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-proxy-token-gkdkp
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: hk8s-worker3
    nodeSelector:
      beta.kubernetes.io/os: linux
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: kube-proxy
    serviceAccountName: kube-proxy
    terminationGracePeriodSeconds: 30
    tolerations:
    - key: CriticalAddonsOnly
      operator: Exists
    - operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - configMap:
        defaultMode: 420
        name: kube-proxy
      name: kube-proxy
    - hostPath:
        path: /run/xtables.lock
        type: FileOrCreate
      name: xtables-lock
    - hostPath:
        path: /lib/modules
        type: ""
      name: lib-modules
    - name: kube-proxy-token-gkdkp
      secret:
        defaultMode: 420
        secretName: kube-proxy-token-gkdkp
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2020-06-03T06:50:43Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2020-06-15T10:02:00Z"
      status: "False"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2020-06-15T10:00:42Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2020-06-03T06:50:43Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://1de6b724c5470c8a842eafd3b2ebee268f666f35221bae3b5596e03d5e068d41
      image: k8s.gcr.io/kube-proxy:v1.16.0
      imageID: docker-pullable://k8s.gcr.io/kube-proxy@sha256:e7f0f8e320cfeeaafdc9c0cb8e23f51e542fa1d955ae39c8131a0531ba72c794
      lastState:
        terminated:
          containerID: docker://fe6bbdea0343c217a03bda0b0056f4c1d86de361470222cced99cc20af6688df
          exitCode: 2
          finishedAt: "2020-06-03T07:11:44Z"
          reason: Error
          startedAt: "2020-06-03T06:50:45Z"
      name: kube-proxy
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2020-06-15T10:00:42Z"
    hostIP: 192.168.122.23
    phase: Running
    podIP: 192.168.122.23
    podIPs:
    - ip: 192.168.122.23
    qosClass: BestEffort
    startTime: "2020-06-03T06:50:43Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2020-01-05T07:46:54Z"
    generateName: kube-proxy-
    labels:
      controller-revision-hash: 68594d95c
      k8s-app: kube-proxy
      pod-template-generation: "1"
    name: kube-proxy-q9ndp
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: kube-proxy
      uid: ce3de9b6-b09b-4e2f-8b76-851ff17ff92f
    resourceVersion: "17996406"
    selfLink: /api/v1/namespaces/kube-system/pods/kube-proxy-q9ndp
    uid: e603354c-49e0-4a9b-926b-683bb12f94a4
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - hk8s-master
    containers:
    - command:
      - /usr/local/bin/kube-proxy
      - --config=/var/lib/kube-proxy/config.conf
      - --hostname-override=$(NODE_NAME)
      env:
      - name: NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      image: k8s.gcr.io/kube-proxy:v1.16.0
      imagePullPolicy: IfNotPresent
      name: kube-proxy
      resources: {}
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/lib/kube-proxy
        name: kube-proxy
      - mountPath: /run/xtables.lock
        name: xtables-lock
      - mountPath: /lib/modules
        name: lib-modules
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-proxy-token-gkdkp
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: hk8s-master
    nodeSelector:
      beta.kubernetes.io/os: linux
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: kube-proxy
    serviceAccountName: kube-proxy
    terminationGracePeriodSeconds: 30
    tolerations:
    - key: CriticalAddonsOnly
      operator: Exists
    - operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - configMap:
        defaultMode: 420
        name: kube-proxy
      name: kube-proxy
    - hostPath:
        path: /run/xtables.lock
        type: FileOrCreate
      name: xtables-lock
    - hostPath:
        path: /lib/modules
        type: ""
      name: lib-modules
    - name: kube-proxy-token-gkdkp
      secret:
        defaultMode: 420
        secretName: kube-proxy-token-gkdkp
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2020-01-05T07:46:54Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2020-06-17T05:56:00Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2020-06-17T05:56:00Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2020-01-05T07:46:54Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://2dbecc9c4963f5cfbefada41e946b583d1fb8d0e4c813d719f88faec85345353
      image: k8s.gcr.io/kube-proxy:v1.16.0
      imageID: docker-pullable://k8s.gcr.io/kube-proxy@sha256:e7f0f8e320cfeeaafdc9c0cb8e23f51e542fa1d955ae39c8131a0531ba72c794
      lastState:
        terminated:
          containerID: docker://c2f9d87329ddf8f150986ee27ccdd71d415fae043a62b35f9c4072c90b6212d6
          exitCode: 2
          finishedAt: "2020-06-16T02:19:11Z"
          reason: Error
          startedAt: "2020-06-08T09:47:26Z"
      name: kube-proxy
      ready: true
      restartCount: 7
      started: true
      state:
        running:
          startedAt: "2020-06-17T05:55:59Z"
    hostIP: 192.168.122.20
    phase: Running
    podIP: 192.168.122.20
    podIPs:
    - ip: 192.168.122.20
    qosClass: BestEffort
    startTime: "2020-01-05T07:46:54Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2020-06-03T03:51:04Z"
    generateName: kube-proxy-
    labels:
      controller-revision-hash: 68594d95c
      k8s-app: kube-proxy
      pod-template-generation: "1"
    name: kube-proxy-vvhft
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: kube-proxy
      uid: ce3de9b6-b09b-4e2f-8b76-851ff17ff92f
    resourceVersion: "17996341"
    selfLink: /api/v1/namespaces/kube-system/pods/kube-proxy-vvhft
    uid: 00878029-1018-45d7-b754-7f7a2dd6cacd
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - hk8s-worker2
    containers:
    - command:
      - /usr/local/bin/kube-proxy
      - --config=/var/lib/kube-proxy/config.conf
      - --hostname-override=$(NODE_NAME)
      env:
      - name: NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      image: k8s.gcr.io/kube-proxy:v1.16.0
      imagePullPolicy: IfNotPresent
      name: kube-proxy
      resources: {}
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/lib/kube-proxy
        name: kube-proxy
      - mountPath: /run/xtables.lock
        name: xtables-lock
      - mountPath: /lib/modules
        name: lib-modules
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-proxy-token-gkdkp
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: hk8s-worker2
    nodeSelector:
      beta.kubernetes.io/os: linux
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: kube-proxy
    serviceAccountName: kube-proxy
    terminationGracePeriodSeconds: 30
    tolerations:
    - key: CriticalAddonsOnly
      operator: Exists
    - operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - configMap:
        defaultMode: 420
        name: kube-proxy
      name: kube-proxy
    - hostPath:
        path: /run/xtables.lock
        type: FileOrCreate
      name: xtables-lock
    - hostPath:
        path: /lib/modules
        type: ""
      name: lib-modules
    - name: kube-proxy-token-gkdkp
      secret:
        defaultMode: 420
        secretName: kube-proxy-token-gkdkp
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2020-06-03T03:51:05Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2020-06-17T05:55:54Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2020-06-17T05:55:54Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2020-06-03T03:51:04Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://a42c2827a520941d9edf3537992c5c5bcde178a4d53f94ef2659c71444241747
      image: k8s.gcr.io/kube-proxy:v1.16.0
      imageID: docker-pullable://k8s.gcr.io/kube-proxy@sha256:e7f0f8e320cfeeaafdc9c0cb8e23f51e542fa1d955ae39c8131a0531ba72c794
      lastState:
        terminated:
          containerID: docker://47ebde0b686a0b1a95f4d161fc880d76d3dbe7105f68a42d051a855d8000cbaf
          exitCode: 2
          finishedAt: "2020-06-16T02:18:29Z"
          reason: Error
          startedAt: "2020-06-08T09:47:25Z"
      name: kube-proxy
      ready: true
      restartCount: 2
      started: true
      state:
        running:
          startedAt: "2020-06-17T05:55:51Z"
    hostIP: 192.168.122.22
    phase: Running
    podIP: 192.168.122.22
    podIPs:
    - ip: 192.168.122.22
    qosClass: BestEffort
    startTime: "2020-06-03T03:51:05Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2020-01-05T07:57:34Z"
    generateName: kube-proxy-
    labels:
      controller-revision-hash: 68594d95c
      k8s-app: kube-proxy
      pod-template-generation: "1"
    name: kube-proxy-wkzb2
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: kube-proxy
      uid: ce3de9b6-b09b-4e2f-8b76-851ff17ff92f
    resourceVersion: "17996306"
    selfLink: /api/v1/namespaces/kube-system/pods/kube-proxy-wkzb2
    uid: 45b57bba-a91e-4691-a5f7-74daa8700108
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - hk8s-worker1
    containers:
    - command:
      - /usr/local/bin/kube-proxy
      - --config=/var/lib/kube-proxy/config.conf
      - --hostname-override=$(NODE_NAME)
      env:
      - name: NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      image: k8s.gcr.io/kube-proxy:v1.16.0
      imagePullPolicy: IfNotPresent
      name: kube-proxy
      resources: {}
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/lib/kube-proxy
        name: kube-proxy
      - mountPath: /run/xtables.lock
        name: xtables-lock
      - mountPath: /lib/modules
        name: lib-modules
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-proxy-token-gkdkp
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: hk8s-worker1
    nodeSelector:
      beta.kubernetes.io/os: linux
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: kube-proxy
    serviceAccountName: kube-proxy
    terminationGracePeriodSeconds: 30
    tolerations:
    - key: CriticalAddonsOnly
      operator: Exists
    - operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - configMap:
        defaultMode: 420
        name: kube-proxy
      name: kube-proxy
    - hostPath:
        path: /run/xtables.lock
        type: FileOrCreate
      name: xtables-lock
    - hostPath:
        path: /lib/modules
        type: ""
      name: lib-modules
    - name: kube-proxy-token-gkdkp
      secret:
        defaultMode: 420
        secretName: kube-proxy-token-gkdkp
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2020-01-05T07:57:34Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2020-06-17T05:55:51Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2020-06-17T05:55:51Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2020-01-05T07:57:34Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://574dadc54f6dd8043159314f364715374aeb7a06d6aa9b2622674132f29e687c
      image: k8s.gcr.io/kube-proxy:v1.16.0
      imageID: docker-pullable://k8s.gcr.io/kube-proxy@sha256:e7f0f8e320cfeeaafdc9c0cb8e23f51e542fa1d955ae39c8131a0531ba72c794
      lastState:
        terminated:
          containerID: docker://347afe3bd035204a0047d90bb41159b78284f3e7659e22c3092c345b91121045
          exitCode: 2
          finishedAt: "2020-06-16T02:18:24Z"
          reason: Error
          startedAt: "2020-06-08T09:47:26Z"
      name: kube-proxy
      ready: true
      restartCount: 7
      started: true
      state:
        running:
          startedAt: "2020-06-17T05:55:49Z"
    hostIP: 192.168.122.21
    phase: Running
    podIP: 192.168.122.21
    podIPs:
    - ip: 192.168.122.21
    qosClass: BestEffort
    startTime: "2020-01-05T07:57:34Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubernetes.io/config.hash: c18ee741ac4ad7b2bfda7d88116f3047
      kubernetes.io/config.mirror: c18ee741ac4ad7b2bfda7d88116f3047
      kubernetes.io/config.seen: "2020-01-05T07:46:04.567598345Z"
      kubernetes.io/config.source: file
    creationTimestamp: "2020-01-05T07:47:45Z"
    labels:
      component: kube-scheduler
      tier: control-plane
    name: kube-scheduler-hk8s-master
    namespace: kube-system
    resourceVersion: "17996248"
    selfLink: /api/v1/namespaces/kube-system/pods/kube-scheduler-hk8s-master
    uid: d4e27b7c-97f2-4aac-867a-5587f46b3589
  spec:
    containers:
    - command:
      - kube-scheduler
      - --authentication-kubeconfig=/etc/kubernetes/scheduler.conf
      - --authorization-kubeconfig=/etc/kubernetes/scheduler.conf
      - --bind-address=127.0.0.1
      - --kubeconfig=/etc/kubernetes/scheduler.conf
      - --leader-elect=true
      image: k8s.gcr.io/kube-scheduler:v1.16.0
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 8
        httpGet:
          host: 127.0.0.1
          path: /healthz
          port: 10251
          scheme: HTTP
        initialDelaySeconds: 15
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      name: kube-scheduler
      resources:
        requests:
          cpu: 100m
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/kubernetes/scheduler.conf
        name: kubeconfig
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: hk8s-master
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      operator: Exists
    volumes:
    - hostPath:
        path: /etc/kubernetes/scheduler.conf
        type: FileOrCreate
      name: kubeconfig
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2020-06-17T05:54:22Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2020-06-17T05:54:40Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2020-06-17T05:54:40Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2020-06-17T05:54:22Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://86603e28d793793ba9b15926f911397b034712553394c68d11c536fd6ddcd782
      image: k8s.gcr.io/kube-scheduler:v1.16.0
      imageID: docker-pullable://k8s.gcr.io/kube-scheduler@sha256:094023ab9cd02059eb0295d234ff9ea321e0e22e4813986d7f1a1ac4dc1990d0
      lastState:
        terminated:
          containerID: docker://cd6933974ca9b93083cc4283b95132c96fd9669554cada02f70aa118073ed555
          exitCode: 2
          finishedAt: "2020-06-16T02:19:11Z"
          reason: Error
          startedAt: "2020-06-08T09:47:04Z"
      name: kube-scheduler
      ready: true
      restartCount: 10
      started: true
      state:
        running:
          startedAt: "2020-06-17T05:54:35Z"
    hostIP: 192.168.122.20
    phase: Running
    podIP: 192.168.122.20
    podIPs:
    - ip: 192.168.122.20
    qosClass: Burstable
    startTime: "2020-06-17T05:54:22Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cni.projectcalico.org/podIP: 192.168.80.109/32
    creationTimestamp: "2020-06-15T06:26:06Z"
    generateName: foo-deploy-85c6dbd77d-
    labels:
      app: foo
      exam: ep
      pod-template-hash: 85c6dbd77d
    name: foo-deploy-85c6dbd77d-2f44q
    namespace: production
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: foo-deploy-85c6dbd77d
      uid: ea064d31-d926-4af4-a72c-af677e7b12b5
    resourceVersion: "17996804"
    selfLink: /api/v1/namespaces/production/pods/foo-deploy-85c6dbd77d-2f44q
    uid: 5b388bdf-bb5f-4e4d-9c36-b0345a1f650b
  spec:
    containers:
    - image: nginx:1.14.2
      imagePullPolicy: IfNotPresent
      name: nginx
      ports:
      - containerPort: 80
        protocol: TCP
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: default-token-xktgp
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: hk8s-worker1
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: default-token-xktgp
      secret:
        defaultMode: 420
        secretName: default-token-xktgp
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2020-06-15T06:26:06Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2020-06-17T05:57:07Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2020-06-17T05:57:07Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2020-06-15T06:26:06Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://dfcee46f7f15e66d5f47bad24f97ad8a6e10b73d8eeb8e699f0895fb0b85ae1e
      image: nginx:1.14.2
      imageID: docker-pullable://nginx@sha256:f7988fb6c02e0ce69257d9bd9cf37ae20a60f1df7563c3a2a6abe24160306b8d
      lastState:
        terminated:
          containerID: docker://7fcdebd272d3815b35c0e6efe56945baa4a71b13b2a34bfa5ff87202c1d815f0
          exitCode: 0
          finishedAt: "2020-06-16T02:18:25Z"
          reason: Completed
          startedAt: "2020-06-15T06:26:35Z"
      name: nginx
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2020-06-17T05:56:59Z"
    hostIP: 192.168.122.21
    phase: Running
    podIP: 192.168.80.109
    podIPs:
    - ip: 192.168.80.109
    qosClass: BestEffort
    startTime: "2020-06-15T06:26:06Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cni.projectcalico.org/podIP: 192.168.80.82/32
    creationTimestamp: "2020-06-15T06:26:06Z"
    generateName: foo-deploy-85c6dbd77d-
    labels:
      app: foo
      exam: ep
      pod-template-hash: 85c6dbd77d
    name: foo-deploy-85c6dbd77d-4rgkv
    namespace: production
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: foo-deploy-85c6dbd77d
      uid: ea064d31-d926-4af4-a72c-af677e7b12b5
    resourceVersion: "17996825"
    selfLink: /api/v1/namespaces/production/pods/foo-deploy-85c6dbd77d-4rgkv
    uid: 8c2056d9-706d-42aa-951c-233b69baf008
  spec:
    containers:
    - image: nginx:1.14.2
      imagePullPolicy: IfNotPresent
      name: nginx
      ports:
      - containerPort: 80
        protocol: TCP
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: default-token-xktgp
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: hk8s-worker1
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: default-token-xktgp
      secret:
        defaultMode: 420
        secretName: default-token-xktgp
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2020-06-15T06:26:06Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2020-06-17T05:57:09Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2020-06-17T05:57:09Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2020-06-15T06:26:06Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://e85380297fd7b48ee2db136f38203cdbc6df686e5f57945d13ea3c22d857d7a9
      image: nginx:1.14.2
      imageID: docker-pullable://nginx@sha256:f7988fb6c02e0ce69257d9bd9cf37ae20a60f1df7563c3a2a6abe24160306b8d
      lastState:
        terminated:
          containerID: docker://80448c0e3036e3af309b7b445f6c6872ce320943a205c7e7af3b5b0b6195c64a
          exitCode: 0
          finishedAt: "2020-06-16T02:18:24Z"
          reason: Completed
          startedAt: "2020-06-15T06:26:38Z"
      name: nginx
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2020-06-17T05:57:06Z"
    hostIP: 192.168.122.21
    phase: Running
    podIP: 192.168.80.82
    podIPs:
    - ip: 192.168.80.82
    qosClass: BestEffort
    startTime: "2020-06-15T06:26:06Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cni.projectcalico.org/podIP: 192.168.192.56/32
    creationTimestamp: "2020-06-15T06:26:06Z"
    generateName: foo-deploy-85c6dbd77d-
    labels:
      app: foo
      exam: ep
      pod-template-hash: 85c6dbd77d
    name: foo-deploy-85c6dbd77d-6cbq5
    namespace: production
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: foo-deploy-85c6dbd77d
      uid: ea064d31-d926-4af4-a72c-af677e7b12b5
    resourceVersion: "17996711"
    selfLink: /api/v1/namespaces/production/pods/foo-deploy-85c6dbd77d-6cbq5
    uid: 6dccd9bf-c0fb-4cca-b27f-077cdcb05cae
  spec:
    containers:
    - image: nginx:1.14.2
      imagePullPolicy: IfNotPresent
      name: nginx
      ports:
      - containerPort: 80
        protocol: TCP
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: default-token-xktgp
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: hk8s-worker2
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: default-token-xktgp
      secret:
        defaultMode: 420
        secretName: default-token-xktgp
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2020-06-15T06:26:06Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2020-06-17T05:56:57Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2020-06-17T05:56:57Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2020-06-15T06:26:06Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://1759bcf21dd9d6f72a749a4566033b0ad89d15ba3183f10377d3fcc03c50dbed
      image: nginx:1.14.2
      imageID: docker-pullable://nginx@sha256:f7988fb6c02e0ce69257d9bd9cf37ae20a60f1df7563c3a2a6abe24160306b8d
      lastState:
        terminated:
          containerID: docker://c7ca49b50531aa38536afc3772fe348598d2bfc4f4c268c067e2a5bbdaea28cf
          exitCode: 0
          finishedAt: "2020-06-16T02:18:29Z"
          reason: Completed
          startedAt: "2020-06-15T06:26:39Z"
      name: nginx
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2020-06-17T05:56:55Z"
    hostIP: 192.168.122.22
    phase: Running
    podIP: 192.168.192.56
    podIPs:
    - ip: 192.168.192.56
    qosClass: BestEffort
    startTime: "2020-06-15T06:26:06Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cni.projectcalico.org/podIP: 192.168.80.88/32
    creationTimestamp: "2020-06-15T06:26:06Z"
    generateName: foo-deploy-85c6dbd77d-
    labels:
      app: foo
      exam: ep
      pod-template-hash: 85c6dbd77d
    name: foo-deploy-85c6dbd77d-g98ml
    namespace: production
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: foo-deploy-85c6dbd77d
      uid: ea064d31-d926-4af4-a72c-af677e7b12b5
    resourceVersion: "17996793"
    selfLink: /api/v1/namespaces/production/pods/foo-deploy-85c6dbd77d-g98ml
    uid: e7d6c296-0ac2-4fbf-969f-fbd981a07858
  spec:
    containers:
    - image: nginx:1.14.2
      imagePullPolicy: IfNotPresent
      name: nginx
      ports:
      - containerPort: 80
        protocol: TCP
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: default-token-xktgp
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: hk8s-worker1
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: default-token-xktgp
      secret:
        defaultMode: 420
        secretName: default-token-xktgp
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2020-06-15T06:26:06Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2020-06-17T05:57:06Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2020-06-17T05:57:06Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2020-06-15T06:26:06Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://c9747301f9c565de26f0ff2a9b48b8e3aecc881e93ca408d5ed44c06b1325f98
      image: nginx:1.14.2
      imageID: docker-pullable://nginx@sha256:f7988fb6c02e0ce69257d9bd9cf37ae20a60f1df7563c3a2a6abe24160306b8d
      lastState:
        terminated:
          containerID: docker://8529ac76bb39afff2ebadd6c384b7968c756f2f513bf9032b0a74c3c5d382fb9
          exitCode: 0
          finishedAt: "2020-06-16T02:18:23Z"
          reason: Completed
          startedAt: "2020-06-15T06:26:41Z"
      name: nginx
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2020-06-17T05:57:03Z"
    hostIP: 192.168.122.21
    phase: Running
    podIP: 192.168.80.88
    podIPs:
    - ip: 192.168.80.88
    qosClass: BestEffort
    startTime: "2020-06-15T06:26:06Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cni.projectcalico.org/podIP: 192.168.192.4/32
    creationTimestamp: "2020-06-15T06:26:06Z"
    generateName: foo-deploy-85c6dbd77d-
    labels:
      app: foo
      exam: ep
      pod-template-hash: 85c6dbd77d
    name: foo-deploy-85c6dbd77d-htv7f
    namespace: production
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: foo-deploy-85c6dbd77d
      uid: ea064d31-d926-4af4-a72c-af677e7b12b5
    resourceVersion: "17996884"
    selfLink: /api/v1/namespaces/production/pods/foo-deploy-85c6dbd77d-htv7f
    uid: 06d7daa8-61c1-4ae9-9552-a17cc9fd6242
  spec:
    containers:
    - image: nginx:1.14.2
      imagePullPolicy: IfNotPresent
      name: nginx
      ports:
      - containerPort: 80
        protocol: TCP
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: default-token-xktgp
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: hk8s-worker2
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: default-token-xktgp
      secret:
        defaultMode: 420
        secretName: default-token-xktgp
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2020-06-15T06:26:06Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2020-06-17T05:57:18Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2020-06-17T05:57:18Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2020-06-15T06:26:06Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://d4bb935a1e091091f695e4c20cf81c99cb6c25a7f0706c110f46b2ea4b9582d4
      image: nginx:1.14.2
      imageID: docker-pullable://nginx@sha256:f7988fb6c02e0ce69257d9bd9cf37ae20a60f1df7563c3a2a6abe24160306b8d
      lastState:
        terminated:
          containerID: docker://aa48988deb41172cbd345034620e5e781c8808c1b855460e346473e5975d96e0
          exitCode: 0
          finishedAt: "2020-06-16T02:18:32Z"
          reason: Completed
          startedAt: "2020-06-15T06:26:33Z"
      name: nginx
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2020-06-17T05:57:12Z"
    hostIP: 192.168.122.22
    phase: Running
    podIP: 192.168.192.4
    podIPs:
    - ip: 192.168.192.4
    qosClass: BestEffort
    startTime: "2020-06-15T06:26:06Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cni.projectcalico.org/podIP: 192.168.192.62/32
    creationTimestamp: "2020-06-15T06:26:06Z"
    generateName: foo-deploy-85c6dbd77d-
    labels:
      app: foo
      exam: ep
      pod-template-hash: 85c6dbd77d
    name: foo-deploy-85c6dbd77d-kh2mx
    namespace: production
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: foo-deploy-85c6dbd77d
      uid: ea064d31-d926-4af4-a72c-af677e7b12b5
    resourceVersion: "17996846"
    selfLink: /api/v1/namespaces/production/pods/foo-deploy-85c6dbd77d-kh2mx
    uid: 4b65739e-88b9-4674-968f-a278c9de1c1d
  spec:
    containers:
    - image: nginx:1.14.2
      imagePullPolicy: IfNotPresent
      name: nginx
      ports:
      - containerPort: 80
        protocol: TCP
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: default-token-xktgp
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: hk8s-worker2
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: default-token-xktgp
      secret:
        defaultMode: 420
        secretName: default-token-xktgp
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2020-06-15T06:26:06Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2020-06-17T05:57:12Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2020-06-17T05:57:12Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2020-06-15T06:26:06Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://297dae080607bfc09a0cfa9f0b91738655e8bde8a1db131ee89c396e79321e97
      image: nginx:1.14.2
      imageID: docker-pullable://nginx@sha256:f7988fb6c02e0ce69257d9bd9cf37ae20a60f1df7563c3a2a6abe24160306b8d
      lastState:
        terminated:
          containerID: docker://2f0236731d5c50561da74d3b03dac324a5612ff8898b19c240d1e8eda6772a99
          exitCode: 0
          finishedAt: "2020-06-16T02:18:29Z"
          reason: Completed
          startedAt: "2020-06-15T06:26:35Z"
      name: nginx
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2020-06-17T05:57:09Z"
    hostIP: 192.168.122.22
    phase: Running
    podIP: 192.168.192.62
    podIPs:
    - ip: 192.168.192.62
    qosClass: BestEffort
    startTime: "2020-06-15T06:26:06Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cni.projectcalico.org/podIP: 192.168.80.66/32
    creationTimestamp: "2020-06-15T06:26:06Z"
    generateName: foo-deploy-85c6dbd77d-
    labels:
      app: foo
      exam: ep
      pod-template-hash: 85c6dbd77d
    name: foo-deploy-85c6dbd77d-qdjg4
    namespace: production
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: foo-deploy-85c6dbd77d
      uid: ea064d31-d926-4af4-a72c-af677e7b12b5
    resourceVersion: "17996809"
    selfLink: /api/v1/namespaces/production/pods/foo-deploy-85c6dbd77d-qdjg4
    uid: bef85cf8-66fd-4e1d-9773-f32a8c2b30a4
  spec:
    containers:
    - image: nginx:1.14.2
      imagePullPolicy: IfNotPresent
      name: nginx
      ports:
      - containerPort: 80
        protocol: TCP
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: default-token-xktgp
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: hk8s-worker1
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: default-token-xktgp
      secret:
        defaultMode: 420
        secretName: default-token-xktgp
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2020-06-15T06:26:06Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2020-06-17T05:57:07Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2020-06-17T05:57:07Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2020-06-15T06:26:06Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://557c4024068406c71f49ad081f39250d2b661c5c7ab86eead2916094fb889446
      image: nginx:1.14.2
      imageID: docker-pullable://nginx@sha256:f7988fb6c02e0ce69257d9bd9cf37ae20a60f1df7563c3a2a6abe24160306b8d
      lastState:
        terminated:
          containerID: docker://9fe41a54e7f8265a695bf43243a6543af28c40965d12ca47243d1e1de79a3d46
          exitCode: 0
          finishedAt: "2020-06-16T02:18:26Z"
          reason: Completed
          startedAt: "2020-06-15T06:26:45Z"
      name: nginx
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2020-06-17T05:57:04Z"
    hostIP: 192.168.122.21
    phase: Running
    podIP: 192.168.80.66
    podIPs:
    - ip: 192.168.80.66
    qosClass: BestEffort
    startTime: "2020-06-15T06:26:06Z"
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""
